{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch = 1.12.1\n",
      "torchvision = 0.13.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "\n",
    "def set_random_seeds(random_seed=0):\n",
    "\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "\n",
    "def memory_check():\n",
    "    print(f\"  Allocated: {round(torch.cuda.memory_allocated()/1024**3,2)} GB\")\n",
    "    print(f\"  Cached:    {round(torch.cuda.memory_reserved()/1024**3,2)} GB\\n\")\n",
    "\n",
    "print(f\"torch = {torch.__version__}\")\n",
    "print(f\"torchvision = {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         QuantStub-1            [-1, 3, 32, 32]               0\n",
      "            Conv2d-2           [-1, 32, 16, 16]             864\n",
      "       BatchNorm2d-3           [-1, 32, 16, 16]              64\n",
      "              ReLU-4           [-1, 32, 16, 16]               0\n",
      "            Conv2d-5           [-1, 32, 16, 16]             288\n",
      "       BatchNorm2d-6           [-1, 32, 16, 16]              64\n",
      "              ReLU-7           [-1, 32, 16, 16]               0\n",
      "            Conv2d-8           [-1, 16, 16, 16]             512\n",
      "       BatchNorm2d-9           [-1, 16, 16, 16]              32\n",
      "QuantizableInvertedResidual-10           [-1, 16, 16, 16]               0\n",
      "           Conv2d-11           [-1, 64, 16, 16]           1,024\n",
      "      BatchNorm2d-12           [-1, 64, 16, 16]             128\n",
      "             ReLU-13           [-1, 64, 16, 16]               0\n",
      "           Conv2d-14             [-1, 64, 8, 8]             576\n",
      "      BatchNorm2d-15             [-1, 64, 8, 8]             128\n",
      "             ReLU-16             [-1, 64, 8, 8]               0\n",
      "           Conv2d-17             [-1, 32, 8, 8]           2,048\n",
      "      BatchNorm2d-18             [-1, 32, 8, 8]              64\n",
      "QuantizableInvertedResidual-19             [-1, 32, 8, 8]               0\n",
      "           Conv2d-20            [-1, 128, 8, 8]           4,096\n",
      "      BatchNorm2d-21            [-1, 128, 8, 8]             256\n",
      "             ReLU-22            [-1, 128, 8, 8]               0\n",
      "           Conv2d-23            [-1, 128, 8, 8]           1,152\n",
      "      BatchNorm2d-24            [-1, 128, 8, 8]             256\n",
      "             ReLU-25            [-1, 128, 8, 8]               0\n",
      "           Conv2d-26             [-1, 32, 8, 8]           4,096\n",
      "      BatchNorm2d-27             [-1, 32, 8, 8]              64\n",
      "         Identity-28             [-1, 32, 8, 8]               0\n",
      "QuantizableInvertedResidual-29             [-1, 32, 8, 8]               0\n",
      "           Conv2d-30            [-1, 128, 8, 8]           4,096\n",
      "      BatchNorm2d-31            [-1, 128, 8, 8]             256\n",
      "             ReLU-32            [-1, 128, 8, 8]               0\n",
      "           Conv2d-33            [-1, 128, 8, 8]           1,152\n",
      "      BatchNorm2d-34            [-1, 128, 8, 8]             256\n",
      "             ReLU-35            [-1, 128, 8, 8]               0\n",
      "           Conv2d-36             [-1, 32, 8, 8]           4,096\n",
      "      BatchNorm2d-37             [-1, 32, 8, 8]              64\n",
      "         Identity-38             [-1, 32, 8, 8]               0\n",
      "QuantizableInvertedResidual-39             [-1, 32, 8, 8]               0\n",
      "           Conv2d-40            [-1, 128, 8, 8]           4,096\n",
      "      BatchNorm2d-41            [-1, 128, 8, 8]             256\n",
      "             ReLU-42            [-1, 128, 8, 8]               0\n",
      "           Conv2d-43            [-1, 128, 4, 4]           1,152\n",
      "      BatchNorm2d-44            [-1, 128, 4, 4]             256\n",
      "             ReLU-45            [-1, 128, 4, 4]               0\n",
      "           Conv2d-46             [-1, 64, 4, 4]           8,192\n",
      "      BatchNorm2d-47             [-1, 64, 4, 4]             128\n",
      "QuantizableInvertedResidual-48             [-1, 64, 4, 4]               0\n",
      "           Conv2d-49            [-1, 256, 4, 4]          16,384\n",
      "      BatchNorm2d-50            [-1, 256, 4, 4]             512\n",
      "             ReLU-51            [-1, 256, 4, 4]               0\n",
      "           Conv2d-52            [-1, 256, 4, 4]           2,304\n",
      "      BatchNorm2d-53            [-1, 256, 4, 4]             512\n",
      "             ReLU-54            [-1, 256, 4, 4]               0\n",
      "           Conv2d-55             [-1, 64, 4, 4]          16,384\n",
      "      BatchNorm2d-56             [-1, 64, 4, 4]             128\n",
      "         Identity-57             [-1, 64, 4, 4]               0\n",
      "QuantizableInvertedResidual-58             [-1, 64, 4, 4]               0\n",
      "           Conv2d-59            [-1, 256, 4, 4]          16,384\n",
      "      BatchNorm2d-60            [-1, 256, 4, 4]             512\n",
      "             ReLU-61            [-1, 256, 4, 4]               0\n",
      "           Conv2d-62            [-1, 256, 4, 4]           2,304\n",
      "      BatchNorm2d-63            [-1, 256, 4, 4]             512\n",
      "             ReLU-64            [-1, 256, 4, 4]               0\n",
      "           Conv2d-65             [-1, 64, 4, 4]          16,384\n",
      "      BatchNorm2d-66             [-1, 64, 4, 4]             128\n",
      "         Identity-67             [-1, 64, 4, 4]               0\n",
      "QuantizableInvertedResidual-68             [-1, 64, 4, 4]               0\n",
      "           Conv2d-69            [-1, 256, 4, 4]          16,384\n",
      "      BatchNorm2d-70            [-1, 256, 4, 4]             512\n",
      "             ReLU-71            [-1, 256, 4, 4]               0\n",
      "           Conv2d-72            [-1, 256, 4, 4]           2,304\n",
      "      BatchNorm2d-73            [-1, 256, 4, 4]             512\n",
      "             ReLU-74            [-1, 256, 4, 4]               0\n",
      "           Conv2d-75             [-1, 64, 4, 4]          16,384\n",
      "      BatchNorm2d-76             [-1, 64, 4, 4]             128\n",
      "         Identity-77             [-1, 64, 4, 4]               0\n",
      "QuantizableInvertedResidual-78             [-1, 64, 4, 4]               0\n",
      "           Conv2d-79            [-1, 256, 4, 4]          16,384\n",
      "      BatchNorm2d-80            [-1, 256, 4, 4]             512\n",
      "             ReLU-81            [-1, 256, 4, 4]               0\n",
      "           Conv2d-82            [-1, 256, 2, 2]           2,304\n",
      "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
      "             ReLU-84            [-1, 256, 2, 2]               0\n",
      "           Conv2d-85            [-1, 128, 2, 2]          32,768\n",
      "      BatchNorm2d-86            [-1, 128, 2, 2]             256\n",
      "QuantizableInvertedResidual-87            [-1, 128, 2, 2]               0\n",
      "           Conv2d-88            [-1, 512, 2, 2]          65,536\n",
      "      BatchNorm2d-89            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-90            [-1, 512, 2, 2]               0\n",
      "           Conv2d-91            [-1, 512, 2, 2]           4,608\n",
      "      BatchNorm2d-92            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-93            [-1, 512, 2, 2]               0\n",
      "           Conv2d-94            [-1, 128, 2, 2]          65,536\n",
      "      BatchNorm2d-95            [-1, 128, 2, 2]             256\n",
      "         Identity-96            [-1, 128, 2, 2]               0\n",
      "QuantizableInvertedResidual-97            [-1, 128, 2, 2]               0\n",
      "           Conv2d-98            [-1, 512, 2, 2]          65,536\n",
      "      BatchNorm2d-99            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-100            [-1, 512, 2, 2]               0\n",
      "          Conv2d-101            [-1, 512, 2, 2]           4,608\n",
      "     BatchNorm2d-102            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-103            [-1, 512, 2, 2]               0\n",
      "          Conv2d-104            [-1, 128, 2, 2]          65,536\n",
      "     BatchNorm2d-105            [-1, 128, 2, 2]             256\n",
      "        Identity-106            [-1, 128, 2, 2]               0\n",
      "QuantizableInvertedResidual-107            [-1, 128, 2, 2]               0\n",
      "          Conv2d-108           [-1, 1280, 2, 2]         163,840\n",
      "     BatchNorm2d-109           [-1, 1280, 2, 2]           2,560\n",
      "            ReLU-110           [-1, 1280, 2, 2]               0\n",
      "         Dropout-111                 [-1, 1280]               0\n",
      "          Linear-112                   [-1, 10]          12,810\n",
      "     DeQuantStub-113                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 656,298\n",
      "Trainable params: 656,298\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.27\n",
      "Params size (MB): 2.50\n",
      "Estimated Total Size (MB): 5.79\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from models import quat_mobilenet_v2\n",
    "tiny_model = quat_mobilenet_v2(cifar10=True)\n",
    "tiny_model.load_state_dict(torch.load(\"./models/tiny_mobilenetv2_cifar.pt\"))\n",
    "summary(tiny_model,(3,32,32),device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([670508])\n",
      "Max 32846.0\n",
      "Min -0.9091643691062927\n",
      "6705\n",
      "tensor(0.5107) tensor(-0.1579)\n",
      "tensor([-0.9092, -0.8394, -0.8371, -0.7841, -0.7512, -0.7318, -0.7111, -0.7075,\n",
      "        -0.7015, -0.6907, -0.6876, -0.6641, -0.6532, -0.6381, -0.6341, -0.6314,\n",
      "        -0.6302, -0.6222, -0.6174, -0.6107])\n"
     ]
    }
   ],
   "source": [
    "tiny_model.to(\"cpu\")\n",
    "with torch.no_grad():\n",
    "    total_tensor = torch.tensor([])\n",
    "    state = tiny_model.state_dict()\n",
    "    for i in state.keys():\n",
    "        new_param = state[i].view(-1)\n",
    "        total_tensor = torch.cat((total_tensor,new_param),0)\n",
    "        \n",
    "    print(total_tensor.shape)\n",
    "    total_tensor,_ = total_tensor.sort()\n",
    "    print(f\"Max {torch.max(total_tensor)}\")\n",
    "    print(f\"Min {torch.min(total_tensor)}\")\n",
    "    number = int(len(total_tensor)*0.01)\n",
    "    print(number)\n",
    "    \n",
    "    M = total_tensor[-number]\n",
    "    m = total_tensor[number]\n",
    "    print(M,m)\n",
    "    print(total_tensor[:20])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1270) tensor(0.1270)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    new_M = 0\n",
    "    new_m = 0 \n",
    "    for name, param in tiny_model.named_parameters():\n",
    "        new_param = param.clamp(m,M)\n",
    "        new_param = torch.round(254*(new_param-m)/(M-m)-127)\n",
    "        new_param = new_param/1000\n",
    "        \n",
    "        new_M = max(new_M,torch.max(new_param))\n",
    "        new_m = max(new_m,torch.max(new_param))\n",
    "    print(new_M,new_m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_quant_model(model:nn.Module,inplace:bool=True):\n",
    "    model.eval()\n",
    "    model.to(\"cpu\")\n",
    "    with torch.no_grad():\n",
    "        state = model.state_dict()\n",
    "        \n",
    "        if not inplace:\n",
    "            new_model = copy.deepcopy(model)\n",
    "        else:\n",
    "            new_model = model\n",
    "    \n",
    "        total_tensor = torch.tensor([])\n",
    "        for i in state.keys():\n",
    "            new_param = state[i].view(-1)\n",
    "            total_tensor = torch.cat((total_tensor,new_param),0)\n",
    "\n",
    "        total_tensor,_ = total_tensor.sort()\n",
    "        number = int(len(total_tensor)*0.05)\n",
    "        \n",
    "        # M = total_tensor[-number]\n",
    "        # m = total_tensor[number]\n",
    "        M = torch.max(total_tensor)\n",
    "        m = torch.min(total_tensor)\n",
    "        print(f\"Max weight : {M}\")\n",
    "        print(f\"Min weight : {m}\")\n",
    "        for i in state.keys():\n",
    "            param = state[i]\n",
    "            new_param = param.clamp(m,M)\n",
    "            new_param = torch.round(254*(new_param-m)/(M-m)-127)\n",
    "            new_param = new_param\n",
    "            # param.data = torch.quantize_per_tensor(new_param, 0.1, 10, torch.quint8)\n",
    "            state[i] = new_param\n",
    "        \n",
    "        new_model.load_state_dict(state)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 tensor(0.5626, grad_fn=<MaxBackward1>) tensor(-0.4744, grad_fn=<MinBackward1>)\n",
      "Max weight : 32846.0\n",
      "Min weight : -0.9091643691062927\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train data set = 50000, Test = 10000\n",
      "Max weight : 127.0\n",
      "Min weight : -127.0\n",
      "calibrating ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from utils import Train\n",
    "\n",
    "quat_model = copy.deepcopy(tiny_model)\n",
    "quat_model.fuse_model()\n",
    "for name, param in quat_model.named_parameters():\n",
    "    print(param.dtype,torch.max(param), torch.min(param))\n",
    "    break\n",
    "quat_model = custom_quant_model(quat_model)\n",
    "train_loader, test_loader = Train.Cifar10_Dataloader()\n",
    "\n",
    "total_tensor = torch.tensor([])\n",
    "state= quat_model.state_dict()\n",
    "for i in state.keys():\n",
    "    new_param = state[i].view(-1)\n",
    "    total_tensor = torch.cat((total_tensor,new_param),0)\n",
    "M = torch.max(total_tensor)\n",
    "m = torch.min(total_tensor)\n",
    "print(f\"Max weight : {M}\")\n",
    "print(f\"Min weight : {m}\")\n",
    "\n",
    "def calibrate_model(model, loader, device=torch.device(\"cpu\")):\n",
    "    print(\"calibrating ...\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for inputs, labels in tqdm((loader),leave=False):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        _ = model(inputs)\n",
    "        \n",
    "calibrate_model(quat_model,test_loader)\n",
    "_,val_acc = Train.Evaluating(quat_model,test_loader,device='cuda')\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tensor : 2.7537312507629395\n",
      "Min tensor : -2.429065704345703\n"
     ]
    }
   ],
   "source": [
    "for img, label in iter(train_loader):\n",
    "    with torch.no_grad():\n",
    "        print(f\"Max tensor : {torch.max(img)}\")\n",
    "        print(f\"Min tensor : {torch.min(img)}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train data set = 50000, Test = 10000\n"
     ]
    }
   ],
   "source": [
    "from utils import Train\n",
    "train_dataset, test_dataset = Train.Cifar10_Dataloader(quantize=True,only_dataset=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670508\n",
      "tensor(32846.) tensor(-0.9092)\n",
      "tensor([-0.9092, -0.8394, -0.8371, -0.7841, -0.7512, -0.7318, -0.7111, -0.7075,\n",
      "        -0.7015, -0.6907, -0.6876, -0.6641, -0.6532, -0.6381, -0.6341, -0.6314,\n",
      "        -0.6302, -0.6222, -0.6174, -0.6107])\n",
      "tensor([32846., 32846., 32846., 32846., 32846., 32846., 32846., 32846., 32846.,\n",
      "        32846., 32846., 32846., 32846., 32846., 32846., 32846., 32846., 32846.,\n",
      "        32846., 32846.])\n"
     ]
    }
   ],
   "source": [
    "fuse_model = copy.deepcopy(tiny_model)\n",
    "fuse_model.fuse_model()\n",
    "state = fuse_model.state_dict()\n",
    "total_tensor = torch.tensor([])\n",
    "for i in state.keys():\n",
    "    new_param = state[i].view(-1)\n",
    "    total_tensor = torch.cat((total_tensor,new_param),0)\n",
    "length = len(total_tensor)\n",
    "total_tensor,_ = total_tensor.sort()\n",
    "print(length)\n",
    "print(torch.max(total_tensor), torch.min(total_tensor))\n",
    "print(total_tensor[:20])\n",
    "print(total_tensor[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "features\n",
      "features.0\n",
      "features.0.0\n",
      "features.0.1\n",
      "features.0.2\n",
      "features.1\n",
      "features.1.conv\n",
      "features.1.conv.0\n",
      "features.1.conv.0.0\n",
      "features.1.conv.0.1\n",
      "features.1.conv.0.2\n",
      "features.1.conv.1\n",
      "features.1.conv.2\n",
      "features.1.skip_add\n",
      "features.1.skip_add.activation_post_process\n",
      "features.2\n",
      "features.2.conv\n",
      "features.2.conv.0\n",
      "features.2.conv.0.0\n",
      "features.2.conv.0.1\n",
      "features.2.conv.0.2\n",
      "features.2.conv.1\n",
      "features.2.conv.1.0\n",
      "features.2.conv.1.1\n",
      "features.2.conv.1.2\n",
      "features.2.conv.2\n",
      "features.2.conv.3\n",
      "features.2.skip_add\n",
      "features.2.skip_add.activation_post_process\n",
      "features.3\n",
      "features.3.conv\n",
      "features.3.conv.0\n",
      "features.3.conv.0.0\n",
      "features.3.conv.0.1\n",
      "features.3.conv.0.2\n",
      "features.3.conv.1\n",
      "features.3.conv.1.0\n",
      "features.3.conv.1.1\n",
      "features.3.conv.1.2\n",
      "features.3.conv.2\n",
      "features.3.conv.3\n",
      "features.3.skip_add\n",
      "features.3.skip_add.activation_post_process\n",
      "features.4\n",
      "features.4.conv\n",
      "features.4.conv.0\n",
      "features.4.conv.0.0\n",
      "features.4.conv.0.1\n",
      "features.4.conv.0.2\n",
      "features.4.conv.1\n",
      "features.4.conv.1.0\n",
      "features.4.conv.1.1\n",
      "features.4.conv.1.2\n",
      "features.4.conv.2\n",
      "features.4.conv.3\n",
      "features.4.skip_add\n",
      "features.4.skip_add.activation_post_process\n",
      "features.5\n",
      "features.5.conv\n",
      "features.5.conv.0\n",
      "features.5.conv.0.0\n",
      "features.5.conv.0.1\n",
      "features.5.conv.0.2\n",
      "features.5.conv.1\n",
      "features.5.conv.1.0\n",
      "features.5.conv.1.1\n",
      "features.5.conv.1.2\n",
      "features.5.conv.2\n",
      "features.5.conv.3\n",
      "features.5.skip_add\n",
      "features.5.skip_add.activation_post_process\n",
      "features.6\n",
      "features.6.conv\n",
      "features.6.conv.0\n",
      "features.6.conv.0.0\n",
      "features.6.conv.0.1\n",
      "features.6.conv.0.2\n",
      "features.6.conv.1\n",
      "features.6.conv.1.0\n",
      "features.6.conv.1.1\n",
      "features.6.conv.1.2\n",
      "features.6.conv.2\n",
      "features.6.conv.3\n",
      "features.6.skip_add\n",
      "features.6.skip_add.activation_post_process\n",
      "features.7\n",
      "features.7.conv\n",
      "features.7.conv.0\n",
      "features.7.conv.0.0\n",
      "features.7.conv.0.1\n",
      "features.7.conv.0.2\n",
      "features.7.conv.1\n",
      "features.7.conv.1.0\n",
      "features.7.conv.1.1\n",
      "features.7.conv.1.2\n",
      "features.7.conv.2\n",
      "features.7.conv.3\n",
      "features.7.skip_add\n",
      "features.7.skip_add.activation_post_process\n",
      "features.8\n",
      "features.8.conv\n",
      "features.8.conv.0\n",
      "features.8.conv.0.0\n",
      "features.8.conv.0.1\n",
      "features.8.conv.0.2\n",
      "features.8.conv.1\n",
      "features.8.conv.1.0\n",
      "features.8.conv.1.1\n",
      "features.8.conv.1.2\n",
      "features.8.conv.2\n",
      "features.8.conv.3\n",
      "features.8.skip_add\n",
      "features.8.skip_add.activation_post_process\n",
      "features.9\n",
      "features.9.conv\n",
      "features.9.conv.0\n",
      "features.9.conv.0.0\n",
      "features.9.conv.0.1\n",
      "features.9.conv.0.2\n",
      "features.9.conv.1\n",
      "features.9.conv.1.0\n",
      "features.9.conv.1.1\n",
      "features.9.conv.1.2\n",
      "features.9.conv.2\n",
      "features.9.conv.3\n",
      "features.9.skip_add\n",
      "features.9.skip_add.activation_post_process\n",
      "features.10\n",
      "features.10.conv\n",
      "features.10.conv.0\n",
      "features.10.conv.0.0\n",
      "features.10.conv.0.1\n",
      "features.10.conv.0.2\n",
      "features.10.conv.1\n",
      "features.10.conv.1.0\n",
      "features.10.conv.1.1\n",
      "features.10.conv.1.2\n",
      "features.10.conv.2\n",
      "features.10.conv.3\n",
      "features.10.skip_add\n",
      "features.10.skip_add.activation_post_process\n",
      "features.11\n",
      "features.11.conv\n",
      "features.11.conv.0\n",
      "features.11.conv.0.0\n",
      "features.11.conv.0.1\n",
      "features.11.conv.0.2\n",
      "features.11.conv.1\n",
      "features.11.conv.1.0\n",
      "features.11.conv.1.1\n",
      "features.11.conv.1.2\n",
      "features.11.conv.2\n",
      "features.11.conv.3\n",
      "features.11.skip_add\n",
      "features.11.skip_add.activation_post_process\n",
      "features.12\n",
      "features.12.0\n",
      "features.12.1\n",
      "features.12.2\n",
      "classifier\n",
      "classifier.0\n",
      "classifier.1\n",
      "quant\n",
      "dequant\n"
     ]
    }
   ],
   "source": [
    "tiny_model.to(\"cpu\")\n",
    "tiny_model.eval()\n",
    "with torch.no_grad():\n",
    "    for img, label in iter(test_loader):\n",
    "        for name, module in tiny_model.named_modules():\n",
    "            print(name)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n",
      "<built-in method dim of Tensor object at 0x7f734a4deb30>\n",
      "Before quant torch.Size([1, 3, 32, 32])\n",
      "tensor([[[[0.7015, 0.0094, 0.6844,  ..., 0.9708, 0.9056, 0.4092],\n",
      "          [0.4952, 0.8349, 0.2106,  ..., 0.1093, 0.3152, 0.3218],\n",
      "          [0.9619, 0.2924, 0.7515,  ..., 0.0749, 0.6031, 0.9446],\n",
      "          ...,\n",
      "          [0.6778, 0.7219, 0.6975,  ..., 0.5404, 0.7204, 0.2027],\n",
      "          [0.4839, 0.5764, 0.8945,  ..., 0.7231, 0.9630, 0.8795],\n",
      "          [0.2107, 0.4932, 0.2533,  ..., 0.0445, 0.0238, 0.9571]],\n",
      "\n",
      "         [[0.3503, 0.7456, 0.3864,  ..., 0.5104, 0.3343, 0.2511],\n",
      "          [0.6302, 0.4099, 0.0470,  ..., 0.6817, 0.0322, 0.0287],\n",
      "          [0.2448, 0.3077, 0.5786,  ..., 0.6606, 0.3641, 0.2507],\n",
      "          ...,\n",
      "          [0.2450, 0.5552, 0.5145,  ..., 0.0156, 0.4594, 0.5732],\n",
      "          [0.6668, 0.1426, 0.4182,  ..., 0.2259, 0.1909, 0.5003],\n",
      "          [0.1236, 0.4521, 0.3786,  ..., 0.4592, 0.4758, 0.9741]],\n",
      "\n",
      "         [[0.6547, 0.3612, 0.9795,  ..., 0.2076, 0.9859, 0.3400],\n",
      "          [0.2913, 0.2355, 0.6658,  ..., 0.7618, 0.8023, 0.9267],\n",
      "          [0.3454, 0.9834, 0.1981,  ..., 0.0507, 0.3846, 0.4739],\n",
      "          ...,\n",
      "          [0.2189, 0.7687, 0.1292,  ..., 0.3286, 0.2500, 0.3276],\n",
      "          [0.9208, 0.3644, 0.2846,  ..., 0.4540, 0.1889, 0.7651],\n",
      "          [0.2058, 0.4979, 0.6666,  ..., 0.7686, 0.9347, 0.0436]]]])\n",
      "\n",
      "After quant\n",
      "tensor([[[[0.7015, 0.0094, 0.6844,  ..., 0.9708, 0.9056, 0.4092],\n",
      "          [0.4952, 0.8349, 0.2106,  ..., 0.1093, 0.3152, 0.3218],\n",
      "          [0.9619, 0.2924, 0.7515,  ..., 0.0749, 0.6031, 0.9446],\n",
      "          ...,\n",
      "          [0.6778, 0.7219, 0.6975,  ..., 0.5404, 0.7204, 0.2027],\n",
      "          [0.4839, 0.5764, 0.8945,  ..., 0.7231, 0.9630, 0.8795],\n",
      "          [0.2107, 0.4932, 0.2533,  ..., 0.0445, 0.0238, 0.9571]],\n",
      "\n",
      "         [[0.3503, 0.7456, 0.3864,  ..., 0.5104, 0.3343, 0.2511],\n",
      "          [0.6302, 0.4099, 0.0470,  ..., 0.6817, 0.0322, 0.0287],\n",
      "          [0.2448, 0.3077, 0.5786,  ..., 0.6606, 0.3641, 0.2507],\n",
      "          ...,\n",
      "          [0.2450, 0.5552, 0.5145,  ..., 0.0156, 0.4594, 0.5732],\n",
      "          [0.6668, 0.1426, 0.4182,  ..., 0.2259, 0.1909, 0.5003],\n",
      "          [0.1236, 0.4521, 0.3786,  ..., 0.4592, 0.4758, 0.9741]],\n",
      "\n",
      "         [[0.6547, 0.3612, 0.9795,  ..., 0.2076, 0.9859, 0.3400],\n",
      "          [0.2913, 0.2355, 0.6658,  ..., 0.7618, 0.8023, 0.9267],\n",
      "          [0.3454, 0.9834, 0.1981,  ..., 0.0507, 0.3846, 0.4739],\n",
      "          ...,\n",
      "          [0.2189, 0.7687, 0.1292,  ..., 0.3286, 0.2500, 0.3276],\n",
      "          [0.9208, 0.3644, 0.2846,  ..., 0.4540, 0.1889, 0.7651],\n",
      "          [0.2058, 0.4979, 0.6666,  ..., 0.7686, 0.9347, 0.0436]]]])\n",
      "\n",
      "Before dequant\n",
      "tensor([[-0.0149, -0.0047, -0.0055, -0.0079, -0.0012, -0.0014, -0.0030,  0.0033,\n",
      "          0.0065,  0.0024]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "After dequant\n",
      "tensor([[-0.0149, -0.0047, -0.0055, -0.0079, -0.0012, -0.0014, -0.0030,  0.0033,\n",
      "          0.0065,  0.0024]], grad_fn=<AddmmBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models import Quant_ReLU\n",
    "from models import quat_mobilenet_v2\n",
    "import torch\n",
    "test_model = quat_mobilenet_v2(cifar10=True, activation_layer = Quant_ReLU)\n",
    "x = torch.rand(1,3,32,32)\n",
    "print(x.shape)\n",
    "print(x.dim)\n",
    "test_model.eval()\n",
    "test_model.to('cpu')\n",
    "y = test_model(x,check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train data set = 50000, Test = 10000\n"
     ]
    }
   ],
   "source": [
    "from models import quat_mobilenet_v2,mobilenet_v2\n",
    "from models import Quant_ReLU\n",
    "from torchsummary import summary\n",
    "from utils import Data\n",
    "from utils import Train\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils.Train import Evaluating\n",
    "from utils.Train import custom_quant_weights,custom_dequant_weights\n",
    "from models.mobilenetv2 import replace_Qrelu, replace_relu, MobileNet_V2_Weights\n",
    "from utils import set_random_seeds\n",
    "# device \n",
    "if torch.cuda.is_available():\n",
    "    gpu_device = torch.device(\"cuda\")\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "\n",
    "# set random \n",
    "set_random_seeds(42)\n",
    "\n",
    "# model load\n",
    "model = quat_mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1,activation_layer=torch.nn.ReLU)\n",
    "model.classifier.append(torch.nn.Dropout(0.2))\n",
    "model.classifier.append(torch.nn.Linear(1000, 10))\n",
    "model.load_state_dict(torch.load(\"./models/mobilenetv2_cifar10.pt\"))\n",
    "# model = mobilenet_v2(cifar10=True)\n",
    "# summary(model,(3,32,32),device=\"cpu\")\n",
    "# data load\n",
    "train_loader, test_loader = Data.Cifar10_Dataloader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train data set = 50000, Test = 10000\n",
      "Before Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation 0.3452 Loss, 90.60 Acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------1----------\n",
      "Train 0.1846 Loss, 95.85 Acc\n",
      "Validation 0.3071 Loss, 90.73 Acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------2----------\n",
      "Train 0.1479 Loss, 95.67 Acc\n",
      "Validation 0.3043 Loss, 90.78 Acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------3----------\n",
      "Train 0.1310 Loss, 95.89 Acc\n",
      "Validation 0.3083 Loss, 90.93 Acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------4----------\n",
      "Train 0.1292 Loss, 95.85 Acc\n",
      "Validation 0.3151 Loss, 90.82 Acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------5----------\n",
      "Train 0.1275 Loss, 95.84 Acc\n",
      "Validation 0.3189 Loss, 90.85 Acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------6----------\n",
      "Train 0.1235 Loss, 95.92 Acc\n",
      "Validation 0.3217 Loss, 90.74 Acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------7----------\n",
      "Train 0.1227 Loss, 96.05 Acc\n",
      "Validation 0.3224 Loss, 90.81 Acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------8----------\n",
      "Train 0.1217 Loss, 96.01 Acc\n",
      "Validation 0.3212 Loss, 90.88 Acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------9----------\n",
      "Train 0.1198 Loss, 96.09 Acc\n",
      "Validation 0.3238 Loss, 90.81 Acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------10----------\n",
      "Train 0.1231 Loss, 95.92 Acc\n",
      "Validation 0.3203 Loss, 90.83 Acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------11----------\n",
      "Train 0.1214 Loss, 96.02 Acc\n",
      "Validation 0.3218 Loss, 90.81 Acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------12----------\n",
      "Train 0.1225 Loss, 95.93 Acc\n",
      "Validation 0.3218 Loss, 90.77 Acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------13----------\n",
      "Train 0.1184 Loss, 96.08 Acc\n",
      "Validation 0.3219 Loss, 90.74 Acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "# optimizer \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# scheduler \n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[20,60,90], gamma=0.5)\n",
    "\n",
    "# train model\n",
    "criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "count = 0\n",
    "best_loss = np.Inf\n",
    "# Training\n",
    "model.to(gpu_device)\n",
    "val_loss, val_acc = Evaluating(model,test_loader,device=gpu_device,criterion=criterion)\n",
    "print(\"Before Training\")\n",
    "print(f\"Validation {val_loss:.4f} Loss, {val_acc:.2f} Acc\")\n",
    "\n",
    "# with torch.autograd.set_detect_anomaly(True):\n",
    "for epoch in range(100):\n",
    "\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "    model.train()\n",
    "    for inputs, labels in tqdm(iter(train_loader),leave=False):\n",
    "        inputs = inputs.to(gpu_device)\n",
    "        labels = labels.to(gpu_device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            check = []\n",
    "            for i in range(inputs.size(0)):\n",
    "                M = torch.max(inputs[i])\n",
    "                m = torch.min(inputs[i])\n",
    "                check.append([m,M])\n",
    "                inputs[i] = torch.round(254*(inputs[i]-m)/(M-m)-127)/1000\n",
    "            \n",
    "            for i in range(inputs.size(0)):\n",
    "                m = check[i][0]\n",
    "                M = check[i][1]\n",
    "                inputs[i] = (1000*inputs[i]+127)*(M-m)/254+m\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        # model,backup = custom_quant_weights(model)\n",
    "        # model = custom_dequant_weights(model,backup)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        # statistics\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        running_corrects += (preds == labels).sum().item()\n",
    "        \n",
    "    # Set learning rate scheduler\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_accuracy = 100 * running_corrects / len(train_loader.dataset) \n",
    "\n",
    "    # Evaluation\n",
    "    val_loss, val_acc = Evaluating(model,test_loader,device=gpu_device,criterion=criterion)\n",
    "    print(f\"--------{epoch+1}----------\")\n",
    "    print(f\"Train {train_loss:.4f} Loss, {train_accuracy:.2f} Acc\")\n",
    "    print(f\"Validation {val_loss:.4f} Loss, {val_acc:.2f} Acc\")\n",
    "    if best_loss > val_loss:\n",
    "        best_loss = val_loss\n",
    "        count = 0\n",
    "        torch.save(model.state_dict(), f\"./models/test.pt\")\n",
    "    else:\n",
    "        count +=1\n",
    "        if count > 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q config = QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})\n",
      "calibrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post int8_model acc :80.32 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from models import quantize_model,quat_mobilenet_v2,MobileNet_V2_Weights\n",
    "import copy\n",
    "import torch\n",
    "train_loader, test_loader\n",
    "model = quat_mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1,activation_layer=torch.nn.ReLU)\n",
    "model.classifier.append(torch.nn.Dropout(0.2))\n",
    "model.classifier.append(torch.nn.Linear(1000, 10))\n",
    "model.to('cpu')\n",
    "model.load_state_dict(torch.load(\"./models/test.pt\"))\n",
    "quat_model = copy.deepcopy(model)\n",
    "quantize_model(quat_model, data= test_loader)\n",
    "_,int8_acc = Evaluating(quat_model,test_loader,\"cpu\")\n",
    "print(f\"post int8_model acc :{int8_acc:.2f} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q config = QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})\n",
      "calibrating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post int8_model acc :68.55 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_state_dict(torch.load(\"./models/mobilenetv2_cifar10.pt\"))\n",
    "quat_model = copy.deepcopy(model)\n",
    "quantize_model(quat_model, data= test_loader)\n",
    "_,int8_acc = Evaluating(quat_model,test_loader,\"cpu\")\n",
    "print(f\"post int8_model acc :{int8_acc:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24c3f2c56578ca93d34255952c36601b421b6ecc37a0d9982e6b92a246c07692"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
