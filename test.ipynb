{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch = 1.12.1\n",
      "torchvision = 0.13.1\n",
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "def set_random_seeds(random_seed=0):\n",
    "\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "\n",
    "def memory_check():\n",
    "    print(f\"  Allocated: {round(torch.cuda.memory_allocated()/1024**3,2)} GB\")\n",
    "    print(f\"  Cached:    {round(torch.cuda.memory_reserved()/1024**3,2)} GB\\n\")\n",
    "\n",
    "print(f\"torch = {torch.__version__}\")\n",
    "print(f\"torchvision = {torchvision.__version__}\")\n",
    "set_random_seeds(42)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"1\"  # Set the GPU 1 to use\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_test(model, device, input_size = (1,3,256,256),num_tests=100):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    x = torch.rand(size=input_size).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(10):\n",
    "            _ = model(x)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "\n",
    "        for _ in range(num_tests):\n",
    "            _ = model(x)\n",
    "            torch.cuda.synchronize()\n",
    "        total_time = time.time() - start_time\n",
    "\n",
    "    aver_time = total_time / num_tests\n",
    "    return total_time, aver_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eq_check(model1, model2, device, rtol=1e-04, atol=1e-08, num_tests=100, input_size=(1,3,256,256)):\n",
    "\n",
    "    model1.to(device)\n",
    "    model2.to(device)\n",
    "\n",
    "    for _ in range(num_tests):\n",
    "        x = torch.rand(size=input_size).to(device)\n",
    "        y1 = model1(x).detach().cpu().numpy()\n",
    "        y2 = model2(x).detach().cpu().numpy()\n",
    "        # 배열이 허용 오차범위 abs(a - b) <= (atol + rtol * absolute(b)) 이내면 True\n",
    "        if np.allclose(a=y1, b=y2, rtol=rtol, atol=atol, equal_nan=False) == False:\n",
    "            print(\"Model equivalence test fail\")\n",
    "            print(f\"output size : {y1.size}\")\n",
    "            print(y1)\n",
    "            print(y2)\n",
    "            return False\n",
    "    print(\"Two models equal\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dropout(p=0.2, inplace=False)\n",
      "  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=1000, out_features=10, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 16, 16]             864\n",
      "       BatchNorm2d-2           [-1, 32, 16, 16]              64\n",
      "              ReLU-3           [-1, 32, 16, 16]               0\n",
      "            Conv2d-4           [-1, 32, 16, 16]             288\n",
      "       BatchNorm2d-5           [-1, 32, 16, 16]              64\n",
      "              ReLU-6           [-1, 32, 16, 16]               0\n",
      "            Conv2d-7           [-1, 16, 16, 16]             512\n",
      "       BatchNorm2d-8           [-1, 16, 16, 16]              32\n",
      "  InvertedResidual-9           [-1, 16, 16, 16]               0\n",
      "           Conv2d-10           [-1, 96, 16, 16]           1,536\n",
      "      BatchNorm2d-11           [-1, 96, 16, 16]             192\n",
      "             ReLU-12           [-1, 96, 16, 16]               0\n",
      "           Conv2d-13           [-1, 96, 16, 16]             864\n",
      "      BatchNorm2d-14           [-1, 96, 16, 16]             192\n",
      "             ReLU-15           [-1, 96, 16, 16]               0\n",
      "           Conv2d-16           [-1, 24, 16, 16]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 16, 16]              48\n",
      " InvertedResidual-18           [-1, 24, 16, 16]               0\n",
      "           Conv2d-19          [-1, 144, 16, 16]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 16, 16]             288\n",
      "             ReLU-21          [-1, 144, 16, 16]               0\n",
      "           Conv2d-22          [-1, 144, 16, 16]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 16, 16]             288\n",
      "             ReLU-24          [-1, 144, 16, 16]               0\n",
      "           Conv2d-25           [-1, 24, 16, 16]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 16, 16]              48\n",
      " InvertedResidual-27           [-1, 24, 16, 16]               0\n",
      "           Conv2d-28          [-1, 144, 16, 16]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 16, 16]             288\n",
      "             ReLU-30          [-1, 144, 16, 16]               0\n",
      "           Conv2d-31            [-1, 144, 8, 8]           1,296\n",
      "      BatchNorm2d-32            [-1, 144, 8, 8]             288\n",
      "             ReLU-33            [-1, 144, 8, 8]               0\n",
      "           Conv2d-34             [-1, 32, 8, 8]           4,608\n",
      "      BatchNorm2d-35             [-1, 32, 8, 8]              64\n",
      " InvertedResidual-36             [-1, 32, 8, 8]               0\n",
      "           Conv2d-37            [-1, 192, 8, 8]           6,144\n",
      "      BatchNorm2d-38            [-1, 192, 8, 8]             384\n",
      "             ReLU-39            [-1, 192, 8, 8]               0\n",
      "           Conv2d-40            [-1, 192, 8, 8]           1,728\n",
      "      BatchNorm2d-41            [-1, 192, 8, 8]             384\n",
      "             ReLU-42            [-1, 192, 8, 8]               0\n",
      "           Conv2d-43             [-1, 32, 8, 8]           6,144\n",
      "      BatchNorm2d-44             [-1, 32, 8, 8]              64\n",
      " InvertedResidual-45             [-1, 32, 8, 8]               0\n",
      "           Conv2d-46            [-1, 192, 8, 8]           6,144\n",
      "      BatchNorm2d-47            [-1, 192, 8, 8]             384\n",
      "             ReLU-48            [-1, 192, 8, 8]               0\n",
      "           Conv2d-49            [-1, 192, 8, 8]           1,728\n",
      "      BatchNorm2d-50            [-1, 192, 8, 8]             384\n",
      "             ReLU-51            [-1, 192, 8, 8]               0\n",
      "           Conv2d-52             [-1, 32, 8, 8]           6,144\n",
      "      BatchNorm2d-53             [-1, 32, 8, 8]              64\n",
      " InvertedResidual-54             [-1, 32, 8, 8]               0\n",
      "           Conv2d-55            [-1, 192, 8, 8]           6,144\n",
      "      BatchNorm2d-56            [-1, 192, 8, 8]             384\n",
      "             ReLU-57            [-1, 192, 8, 8]               0\n",
      "           Conv2d-58            [-1, 192, 4, 4]           1,728\n",
      "      BatchNorm2d-59            [-1, 192, 4, 4]             384\n",
      "             ReLU-60            [-1, 192, 4, 4]               0\n",
      "           Conv2d-61             [-1, 64, 4, 4]          12,288\n",
      "      BatchNorm2d-62             [-1, 64, 4, 4]             128\n",
      " InvertedResidual-63             [-1, 64, 4, 4]               0\n",
      "           Conv2d-64            [-1, 384, 4, 4]          24,576\n",
      "      BatchNorm2d-65            [-1, 384, 4, 4]             768\n",
      "             ReLU-66            [-1, 384, 4, 4]               0\n",
      "           Conv2d-67            [-1, 384, 4, 4]           3,456\n",
      "      BatchNorm2d-68            [-1, 384, 4, 4]             768\n",
      "             ReLU-69            [-1, 384, 4, 4]               0\n",
      "           Conv2d-70             [-1, 64, 4, 4]          24,576\n",
      "      BatchNorm2d-71             [-1, 64, 4, 4]             128\n",
      " InvertedResidual-72             [-1, 64, 4, 4]               0\n",
      "           Conv2d-73            [-1, 384, 4, 4]          24,576\n",
      "      BatchNorm2d-74            [-1, 384, 4, 4]             768\n",
      "             ReLU-75            [-1, 384, 4, 4]               0\n",
      "           Conv2d-76            [-1, 384, 4, 4]           3,456\n",
      "      BatchNorm2d-77            [-1, 384, 4, 4]             768\n",
      "             ReLU-78            [-1, 384, 4, 4]               0\n",
      "           Conv2d-79             [-1, 64, 4, 4]          24,576\n",
      "      BatchNorm2d-80             [-1, 64, 4, 4]             128\n",
      " InvertedResidual-81             [-1, 64, 4, 4]               0\n",
      "           Conv2d-82            [-1, 384, 4, 4]          24,576\n",
      "      BatchNorm2d-83            [-1, 384, 4, 4]             768\n",
      "             ReLU-84            [-1, 384, 4, 4]               0\n",
      "           Conv2d-85            [-1, 384, 4, 4]           3,456\n",
      "      BatchNorm2d-86            [-1, 384, 4, 4]             768\n",
      "             ReLU-87            [-1, 384, 4, 4]               0\n",
      "           Conv2d-88             [-1, 64, 4, 4]          24,576\n",
      "      BatchNorm2d-89             [-1, 64, 4, 4]             128\n",
      " InvertedResidual-90             [-1, 64, 4, 4]               0\n",
      "           Conv2d-91            [-1, 384, 4, 4]          24,576\n",
      "      BatchNorm2d-92            [-1, 384, 4, 4]             768\n",
      "             ReLU-93            [-1, 384, 4, 4]               0\n",
      "           Conv2d-94            [-1, 384, 4, 4]           3,456\n",
      "      BatchNorm2d-95            [-1, 384, 4, 4]             768\n",
      "             ReLU-96            [-1, 384, 4, 4]               0\n",
      "           Conv2d-97             [-1, 96, 4, 4]          36,864\n",
      "      BatchNorm2d-98             [-1, 96, 4, 4]             192\n",
      " InvertedResidual-99             [-1, 96, 4, 4]               0\n",
      "          Conv2d-100            [-1, 576, 4, 4]          55,296\n",
      "     BatchNorm2d-101            [-1, 576, 4, 4]           1,152\n",
      "            ReLU-102            [-1, 576, 4, 4]               0\n",
      "          Conv2d-103            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-104            [-1, 576, 4, 4]           1,152\n",
      "            ReLU-105            [-1, 576, 4, 4]               0\n",
      "          Conv2d-106             [-1, 96, 4, 4]          55,296\n",
      "     BatchNorm2d-107             [-1, 96, 4, 4]             192\n",
      "InvertedResidual-108             [-1, 96, 4, 4]               0\n",
      "          Conv2d-109            [-1, 576, 4, 4]          55,296\n",
      "     BatchNorm2d-110            [-1, 576, 4, 4]           1,152\n",
      "            ReLU-111            [-1, 576, 4, 4]               0\n",
      "          Conv2d-112            [-1, 576, 4, 4]           5,184\n",
      "     BatchNorm2d-113            [-1, 576, 4, 4]           1,152\n",
      "            ReLU-114            [-1, 576, 4, 4]               0\n",
      "          Conv2d-115             [-1, 96, 4, 4]          55,296\n",
      "     BatchNorm2d-116             [-1, 96, 4, 4]             192\n",
      "InvertedResidual-117             [-1, 96, 4, 4]               0\n",
      "          Conv2d-118            [-1, 576, 4, 4]          55,296\n",
      "     BatchNorm2d-119            [-1, 576, 4, 4]           1,152\n",
      "            ReLU-120            [-1, 576, 4, 4]               0\n",
      "          Conv2d-121            [-1, 576, 2, 2]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 2, 2]           1,152\n",
      "            ReLU-123            [-1, 576, 2, 2]               0\n",
      "          Conv2d-124            [-1, 160, 2, 2]          92,160\n",
      "     BatchNorm2d-125            [-1, 160, 2, 2]             320\n",
      "InvertedResidual-126            [-1, 160, 2, 2]               0\n",
      "          Conv2d-127            [-1, 960, 2, 2]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 2, 2]           1,920\n",
      "            ReLU-129            [-1, 960, 2, 2]               0\n",
      "          Conv2d-130            [-1, 960, 2, 2]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 2, 2]           1,920\n",
      "            ReLU-132            [-1, 960, 2, 2]               0\n",
      "          Conv2d-133            [-1, 160, 2, 2]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 2, 2]             320\n",
      "InvertedResidual-135            [-1, 160, 2, 2]               0\n",
      "          Conv2d-136            [-1, 960, 2, 2]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 2, 2]           1,920\n",
      "            ReLU-138            [-1, 960, 2, 2]               0\n",
      "          Conv2d-139            [-1, 960, 2, 2]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 2, 2]           1,920\n",
      "            ReLU-141            [-1, 960, 2, 2]               0\n",
      "          Conv2d-142            [-1, 160, 2, 2]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 2, 2]             320\n",
      "InvertedResidual-144            [-1, 160, 2, 2]               0\n",
      "          Conv2d-145            [-1, 960, 2, 2]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 2, 2]           1,920\n",
      "            ReLU-147            [-1, 960, 2, 2]               0\n",
      "          Conv2d-148            [-1, 960, 2, 2]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 2, 2]           1,920\n",
      "            ReLU-150            [-1, 960, 2, 2]               0\n",
      "          Conv2d-151            [-1, 320, 2, 2]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 2, 2]             640\n",
      "InvertedResidual-153            [-1, 320, 2, 2]               0\n",
      "          Conv2d-154           [-1, 1280, 2, 2]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 2, 2]           2,560\n",
      "            ReLU-156           [-1, 1280, 2, 2]               0\n",
      "         Dropout-157                 [-1, 1280]               0\n",
      "          Linear-158                 [-1, 1000]       1,281,000\n",
      "         Dropout-159                 [-1, 1000]               0\n",
      "          Linear-160                   [-1, 10]          10,010\n",
      "================================================================\n",
      "Total params: 3,514,882\n",
      "Trainable params: 3,514,882\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 9.41\n",
      "Params size (MB): 13.41\n",
      "Estimated Total Size (MB): 22.83\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from models import mobilenet_v2, MobileNet_V2_Weights\n",
    "mobilenet = mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1,activation_layer=nn.ReLU)\n",
    "mobilenet.classifier.append(nn.Dropout(0.2))\n",
    "mobilenet.classifier.append(nn.Linear(1000, 10))\n",
    "print(mobilenet.classifier)\n",
    "mobilenet.load_state_dict(torch.load(\"./models/mobilenetv2_cifar10.pt\"))\n",
    "from torchsummary import summary\n",
    "summary(mobilenet,(3,32,32), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.0.weight False\n",
      "features.0.1.weight False\n",
      "features.0.1.bias False\n",
      "features.1.conv.0.0.weight False\n",
      "features.1.conv.0.1.weight False\n",
      "features.1.conv.0.1.bias False\n",
      "features.1.conv.1.weight False\n",
      "features.1.conv.2.weight False\n",
      "features.1.conv.2.bias False\n",
      "features.2.conv.0.0.weight False\n",
      "features.2.conv.0.1.weight False\n",
      "features.2.conv.0.1.bias False\n",
      "features.2.conv.1.0.weight False\n",
      "features.2.conv.1.1.weight False\n",
      "features.2.conv.1.1.bias False\n",
      "features.2.conv.2.weight False\n",
      "features.2.conv.3.weight False\n",
      "features.2.conv.3.bias False\n",
      "features.3.conv.0.0.weight False\n",
      "features.3.conv.0.1.weight False\n",
      "features.3.conv.0.1.bias False\n",
      "features.3.conv.1.0.weight False\n",
      "features.3.conv.1.1.weight False\n",
      "features.3.conv.1.1.bias False\n",
      "features.3.conv.2.weight False\n",
      "features.3.conv.3.weight False\n",
      "features.3.conv.3.bias False\n",
      "features.4.conv.0.0.weight False\n",
      "features.4.conv.0.1.weight False\n",
      "features.4.conv.0.1.bias False\n",
      "features.4.conv.1.0.weight False\n",
      "features.4.conv.1.1.weight False\n",
      "features.4.conv.1.1.bias False\n",
      "features.4.conv.2.weight False\n",
      "features.4.conv.3.weight False\n",
      "features.4.conv.3.bias False\n",
      "features.5.conv.0.0.weight False\n",
      "features.5.conv.0.1.weight False\n",
      "features.5.conv.0.1.bias False\n",
      "features.5.conv.1.0.weight False\n",
      "features.5.conv.1.1.weight False\n",
      "features.5.conv.1.1.bias False\n",
      "features.5.conv.2.weight False\n",
      "features.5.conv.3.weight False\n",
      "features.5.conv.3.bias False\n",
      "features.6.conv.0.0.weight False\n",
      "features.6.conv.0.1.weight False\n",
      "features.6.conv.0.1.bias False\n",
      "features.6.conv.1.0.weight False\n",
      "features.6.conv.1.1.weight False\n",
      "features.6.conv.1.1.bias False\n",
      "features.6.conv.2.weight False\n",
      "features.6.conv.3.weight False\n",
      "features.6.conv.3.bias False\n",
      "features.7.conv.0.0.weight False\n",
      "features.7.conv.0.1.weight False\n",
      "features.7.conv.0.1.bias False\n",
      "features.7.conv.1.0.weight False\n",
      "features.7.conv.1.1.weight False\n",
      "features.7.conv.1.1.bias False\n",
      "features.7.conv.2.weight False\n",
      "features.7.conv.3.weight False\n",
      "features.7.conv.3.bias False\n",
      "features.8.conv.0.0.weight False\n",
      "features.8.conv.0.1.weight False\n",
      "features.8.conv.0.1.bias False\n",
      "features.8.conv.1.0.weight False\n",
      "features.8.conv.1.1.weight False\n",
      "features.8.conv.1.1.bias False\n",
      "features.8.conv.2.weight False\n",
      "features.8.conv.3.weight False\n",
      "features.8.conv.3.bias False\n",
      "features.9.conv.0.0.weight False\n",
      "features.9.conv.0.1.weight False\n",
      "features.9.conv.0.1.bias False\n",
      "features.9.conv.1.0.weight False\n",
      "features.9.conv.1.1.weight False\n",
      "features.9.conv.1.1.bias False\n",
      "features.9.conv.2.weight False\n",
      "features.9.conv.3.weight False\n",
      "features.9.conv.3.bias False\n",
      "features.10.conv.0.0.weight False\n",
      "features.10.conv.0.1.weight False\n",
      "features.10.conv.0.1.bias False\n",
      "features.10.conv.1.0.weight False\n",
      "features.10.conv.1.1.weight False\n",
      "features.10.conv.1.1.bias False\n",
      "features.10.conv.2.weight False\n",
      "features.10.conv.3.weight False\n",
      "features.10.conv.3.bias False\n",
      "features.11.conv.0.0.weight False\n",
      "features.11.conv.0.1.weight False\n",
      "features.11.conv.0.1.bias False\n",
      "features.11.conv.1.0.weight False\n",
      "features.11.conv.1.1.weight False\n",
      "features.11.conv.1.1.bias False\n",
      "features.11.conv.2.weight False\n",
      "features.11.conv.3.weight False\n",
      "features.11.conv.3.bias False\n",
      "features.12.conv.0.0.weight False\n",
      "features.12.conv.0.1.weight False\n",
      "features.12.conv.0.1.bias False\n",
      "features.12.conv.1.0.weight False\n",
      "features.12.conv.1.1.weight False\n",
      "features.12.conv.1.1.bias False\n",
      "features.12.conv.2.weight False\n",
      "features.12.conv.3.weight False\n",
      "features.12.conv.3.bias False\n",
      "features.13.conv.0.0.weight False\n",
      "features.13.conv.0.1.weight False\n",
      "features.13.conv.0.1.bias False\n",
      "features.13.conv.1.0.weight False\n",
      "features.13.conv.1.1.weight False\n",
      "features.13.conv.1.1.bias False\n",
      "features.13.conv.2.weight False\n",
      "features.13.conv.3.weight False\n",
      "features.13.conv.3.bias False\n",
      "features.14.conv.0.0.weight False\n",
      "features.14.conv.0.1.weight False\n",
      "features.14.conv.0.1.bias False\n",
      "features.14.conv.1.0.weight False\n",
      "features.14.conv.1.1.weight False\n",
      "features.14.conv.1.1.bias False\n",
      "features.14.conv.2.weight False\n",
      "features.14.conv.3.weight False\n",
      "features.14.conv.3.bias False\n",
      "features.15.conv.0.0.weight False\n",
      "features.15.conv.0.1.weight False\n",
      "features.15.conv.0.1.bias False\n",
      "features.15.conv.1.0.weight False\n",
      "features.15.conv.1.1.weight False\n",
      "features.15.conv.1.1.bias False\n",
      "features.15.conv.2.weight False\n",
      "features.15.conv.3.weight False\n",
      "features.15.conv.3.bias False\n",
      "features.16.conv.0.0.weight False\n",
      "features.16.conv.0.1.weight False\n",
      "features.16.conv.0.1.bias False\n",
      "features.16.conv.1.0.weight False\n",
      "features.16.conv.1.1.weight False\n",
      "features.16.conv.1.1.bias False\n",
      "features.16.conv.2.weight False\n",
      "features.16.conv.3.weight False\n",
      "features.16.conv.3.bias False\n",
      "features.17.conv.0.0.weight False\n",
      "features.17.conv.0.1.weight False\n",
      "features.17.conv.0.1.bias False\n",
      "features.17.conv.1.0.weight False\n",
      "features.17.conv.1.1.weight False\n",
      "features.17.conv.1.1.bias False\n",
      "features.17.conv.2.weight False\n",
      "features.17.conv.3.weight False\n",
      "features.17.conv.3.bias False\n",
      "features.18.0.weight False\n",
      "features.18.1.weight False\n",
      "features.18.1.bias False\n",
      "classifier.1.weight True\n",
      "classifier.1.bias True\n",
      "classifier.3.weight True\n",
      "classifier.3.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, param in mobilenet.named_parameters():\n",
    "    if \"features\" in name:\n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def bit2float(b, num_e_bits=8, num_m_bits=23, bias=127.):\n",
    "  \"\"\"Turn input tensor into float.\n",
    "      Args:\n",
    "          b : binary tensor. The last dimension of this tensor should be the\n",
    "          the one the binary is at.\n",
    "          num_e_bits : Number of exponent bits. Default: 8.\n",
    "          num_m_bits : Number of mantissa bits. Default: 23.\n",
    "          bias : Exponent bias/ zero offset. Default: 127.\n",
    "      Returns:\n",
    "          Tensor: Float tensor. Reduces last dimension.\n",
    "  \"\"\"\n",
    "  expected_last_dim = num_m_bits + num_e_bits + 1\n",
    "  assert b.shape[-1] == expected_last_dim, \"Binary tensors last dimension \" \\\n",
    "                                           \"should be {}, not {}.\".format(\n",
    "    expected_last_dim, b.shape[-1])\n",
    "\n",
    "  # check if we got the right type\n",
    "  dtype = torch.float32\n",
    "  if expected_last_dim > 32: dtype = torch.float64\n",
    "  if expected_last_dim > 64:\n",
    "    warnings.warn(\"pytorch can not process floats larger than 64 bits, keep\"\n",
    "                  \" this in mind. Your result will be not exact.\")\n",
    "\n",
    "  s = torch.index_select(b, -1, torch.arange(0, 1))\n",
    "  e = torch.index_select(b, -1, torch.arange(1, 1 + num_e_bits))\n",
    "  m = torch.index_select(b, -1, torch.arange(1 + num_e_bits,\n",
    "                                             1 + num_e_bits + num_m_bits))\n",
    "  # SIGN BIT\n",
    "  out = ((-1) ** s).squeeze(-1).type(dtype)\n",
    "  # EXPONENT BIT\n",
    "  exponents = -torch.arange(-(num_e_bits - 1.), 1.)\n",
    "  exponents = exponents.repeat(b.shape[:-1] + (1,))\n",
    "  e_decimal = torch.sum(e * 2 ** exponents, dim=-1) - bias\n",
    "  out *= 2 ** e_decimal\n",
    "  # MANTISSA\n",
    "  matissa = (torch.Tensor([2.]) ** (\n",
    "    -torch.arange(1., num_m_bits + 1.))).repeat(\n",
    "    m.shape[:-1] + (1,))\n",
    "  out *= 1. + torch.sum(m * matissa, dim=-1)\n",
    "  return out\n",
    "\n",
    "def remainder2bit(remainder, num_bits=127):\n",
    "  \"\"\"Turn a tensor with remainders (floats < 1) to mantissa bits.\n",
    "      Args:\n",
    "          remainder : torch.Tensor, tensor with remainders\n",
    "          num_bits : Number of bits to specify the precision. Default: 127.\n",
    "      Returns:\n",
    "          Tensor: Binary tensor. Adds last dimension to original tensor for\n",
    "          bits.\n",
    "  \"\"\"\n",
    "  dtype = remainder.type()\n",
    "  exponent_bits = torch.arange(num_bits).type(dtype)\n",
    "  exponent_bits = exponent_bits.repeat(remainder.shape + (1,))\n",
    "  out = (remainder.unsqueeze(-1) * 2 ** exponent_bits) % 1\n",
    "  return torch.floor(2 * out)\n",
    "\n",
    "\n",
    "def integer2bit(integer, num_bits=8):\n",
    "  \"\"\"Turn integer tensor to binary representation.\n",
    "      Args:\n",
    "          integer : torch.Tensor, tensor with integers\n",
    "          num_bits : Number of bits to specify the precision. Default: 8.\n",
    "      Returns:\n",
    "          Tensor: Binary tensor. Adds last dimension to original tensor for\n",
    "          bits.\n",
    "  \"\"\"\n",
    "  dtype = integer.type()\n",
    "  exponent_bits = -torch.arange(-(num_bits - 1), 1).type(dtype)\n",
    "  exponent_bits = exponent_bits.repeat(integer.shape + (1,))\n",
    "  out = integer.unsqueeze(-1) / 2 ** exponent_bits\n",
    "  return (out - (out % 1)) % 2\n",
    "\n",
    "def float2bit(f, num_e_bits=8, num_m_bits=23, bias=127., dtype=torch.float32):\n",
    "  \"\"\"Turn input tensor into binary.\n",
    "      Args:\n",
    "          f : float tensor.\n",
    "          num_e_bits : Number of exponent bits. Default: 8.\n",
    "          num_m_bits : Number of mantissa bits. Default: 23.\n",
    "          bias : Exponent bias/ zero offset. Default: 127.\n",
    "          dtype : This is the actual type of the tensor that is going to be\n",
    "          returned. Default: torch.float32.\n",
    "      Returns:\n",
    "          Tensor: Binary tensor. Adds last dimension to original tensor for\n",
    "          bits.\n",
    "  \"\"\"\n",
    "  ## SIGN BIT\n",
    "  s = torch.sign(f)\n",
    "  f = f * s\n",
    "  # turn sign into sign-bit\n",
    "  s = (s * (-1) + 1.) * 0.5\n",
    "  s = s.unsqueeze(-1)\n",
    "\n",
    "  ## EXPONENT BIT\n",
    "  e_scientific = torch.floor(torch.log2(f))\n",
    "  e_decimal = e_scientific + bias\n",
    "  e = integer2bit(e_decimal, num_bits=num_e_bits)\n",
    "\n",
    "  ## MANTISSA\n",
    "  m1 = integer2bit(f - f % 1, num_bits=num_e_bits)\n",
    "  m2 = remainder2bit(f % 1, num_bits=bias)\n",
    "  m = torch.cat([m1, m2], dim=-1)\n",
    "  \n",
    "  dtype = f.type()\n",
    "  idx = torch.arange(num_m_bits).unsqueeze(0).type(dtype) \\\n",
    "        + (8. - e_scientific).unsqueeze(-1)\n",
    "  idx = idx.long()\n",
    "  m = torch.gather(m, dim=-1, index=idx)\n",
    "\n",
    "  return torch.cat([s, e, m], dim=-1).type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.float32 torch.Size([32, 3, 3, 3])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n",
      "torch.Size([3, 32])\n"
     ]
    }
   ],
   "source": [
    "int_model = copy.deepcopy(mobilenet)\n",
    "for name, param in int_model.named_parameters():\n",
    "    print(type(param.data),param.dtype,param.shape)\n",
    "    new_param = param.half()\n",
    "    with torch.no_grad():\n",
    "        round_param = torch.round(param.data,decimals=10)\n",
    "    for i in range(len(param)):    \n",
    "        # print(param[p])\n",
    "        p = param.data[i][0][0]\n",
    "        bit = float2bit(p)\n",
    "        print(bit.shape)\n",
    "        # print(bit)\n",
    "        f = bit2float(bit)\n",
    "        if np.allclose(a=p, b=f,rtol=1e-4,atol=1e-4) == False:\n",
    "                print(\"Model equivalence test fail\")\n",
    "                print(p,end='\\n\\n')\n",
    "                print(f)\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5196) tensor(-2.2460)\n"
     ]
    }
   ],
   "source": [
    "M = 0\n",
    "m = 0\n",
    "for name,param in int_model.named_parameters():\n",
    "    M = max(M,param.max())\n",
    "    m = min(m,param.min())\n",
    "print(M,m)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileNet은 fusion 시 속도가 느려짐\n",
    "+\n",
    "output 결과가 다름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((1,3,32,32))\n",
    "print(mobilenet.forward(a).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): Identity()\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144)\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144)\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192)\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576)\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576)\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960)\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960)\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960)\n",
      "          (1): Identity()\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): Conv2dNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Identity()\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=1000, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "fuse_model = copy.deepcopy(mobilenet)\n",
    "fuse_model.eval()\n",
    "for module_name, module in fuse_model.named_children():\n",
    "    if module_name in \"features\":\n",
    "        for block_name, block in module.named_children():\n",
    "            if isinstance(block,torchvision.ops.misc.ConvNormActivation):\n",
    "                torch.ao.quantization.fuse_modules(block,[[\"0\",\"1\"]],inplace=True)\n",
    "            else:\n",
    "                for name, conv in block.named_children():\n",
    "                    # try:\n",
    "                    #     torch.ao.quantization.fuse_modules(conv,[[\"1\",\"2\"]],inplace=True,fuser_func=(nn.Conv2d, nn.BatchNorm2d))\n",
    "                    # except:\n",
    "                    #     torch.ao.quantization.fuse_modules(conv,[[\"2\",\"3\"]],inplace=True,fuser_func=(nn.Conv2d, nn.BatchNorm2d))\n",
    "                                                           \n",
    "                    for cell_name, cell in conv.named_children():\n",
    "                        if isinstance(cell,torchvision.ops.misc.ConvNormActivation):\n",
    "                            torch.ao.quantization.fuse_modules(cell,[[\"0\",\"1\"]],inplace=True,fuser_func=(nn.Conv2d, nn.BatchNorm2d, nn.ReLU))\n",
    "\n",
    "print(fuse_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Equal Test --\n",
      "Model equivalence test fail\n",
      "output size : 10\n",
      "[[-0.10295074 -0.2944044   0.2564814   0.74343145  0.14422883  1.3580137\n",
      "  -0.2582492  -0.03915124 -0.29986712 -0.027831  ]]\n",
      "[[ 0.36052272  0.04072542 -0.7131027  -0.3688231  -0.29279172 -0.01099667\n",
      "   1.3875433  -0.32531443  0.09175906 -0.10298437]]\n",
      "-- Infer Time Test --\n",
      "origin model infer time 1.613s\n",
      "fusion model infer time 1.520s\n"
     ]
    }
   ],
   "source": [
    "print(f\"-- Equal Test --\")\n",
    "model_eq_check(mobilenet, fuse_model, device=torch.device(\"cpu:0\"))\n",
    "\n",
    "\n",
    "print(f\"-- Infer Time Test --\")\n",
    "ori_cpu_time,_ = time_test(mobilenet,torch.device(\"cpu\"))\n",
    "fus_cpu_time,_ = time_test(fuse_model,torch.device(\"cpu\"))\n",
    "\n",
    "print(f\"origin model infer time {ori_cpu_time:.3f}s\")\n",
    "print(f\"fusion model infer time {fus_cpu_time:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvBnReLUModel(\n",
      "  (conv): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "ConvBnReLUModel(\n",
      "  (conv): ConvReLU2d(\n",
      "    (0): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (bn): Identity()\n",
      "  (relu): Identity()\n",
      ")\n",
      "-- Equal Test --\n",
      "Model equivalence test fail\n",
      "output size : 322580\n",
      "[[[[0.         0.04978545 0.18221086 ... 0.19953066 0.12825319\n",
      "    0.2680617 ]\n",
      "   [0.302618   0.25694257 0.         ... 0.03463042 0.\n",
      "    0.11867654]\n",
      "   [0.2761687  0.         0.         ... 0.38341272 0.24167342\n",
      "    0.11720394]\n",
      "   ...\n",
      "   [0.36444092 0.         0.11769357 ... 0.25166047 0.23247495\n",
      "    0.56167454]\n",
      "   [0.07713657 0.31332463 0.17682478 ... 0.         0.31133115\n",
      "    0.18637848]\n",
      "   [0.11211896 0.35029468 0.         ... 0.1000894  0.\n",
      "    0.20824143]]\n",
      "\n",
      "  [[0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]]\n",
      "\n",
      "  [[0.08400626 0.31422442 0.05347282 ... 0.         0.3081212\n",
      "    0.        ]\n",
      "   [0.364507   0.15861599 0.09122105 ... 0.3123259  0.\n",
      "    0.        ]\n",
      "   [0.12457243 0.         0.28509808 ... 0.08540843 0.06493516\n",
      "    0.08951313]\n",
      "   ...\n",
      "   [0.367194   0.         0.02088073 ... 0.         0.32645756\n",
      "    0.15857916]\n",
      "   [0.31254572 0.20956108 0.0549539  ... 0.         0.10131402\n",
      "    0.28503698]\n",
      "   [0.02160891 0.0209521  0.34791306 ... 0.         0.\n",
      "    0.01134946]]\n",
      "\n",
      "  [[0.         0.2513981  0.         ... 0.25217843 0.14240028\n",
      "    0.        ]\n",
      "   [0.3081627  0.25185943 0.02773869 ... 0.16317791 0.\n",
      "    0.2733817 ]\n",
      "   [0.24873494 0.30017382 0.26963958 ... 0.0909318  0.2997449\n",
      "    0.18736911]\n",
      "   ...\n",
      "   [0.13171533 0.         0.1407854  ... 0.0618665  0.1620764\n",
      "    0.25776622]\n",
      "   [0.2897742  0.31915677 0.0956044  ... 0.         0.05067982\n",
      "    0.03760876]\n",
      "   [0.         0.59125614 0.         ... 0.14737444 0.03697865\n",
      "    0.45018357]]\n",
      "\n",
      "  [[0.07612684 0.14646846 0.         ... 0.2227438  0.0947342\n",
      "    0.38002947]\n",
      "   [0.10375783 0.         0.26761302 ... 0.06379261 0.04227639\n",
      "    0.        ]\n",
      "   [0.19828714 0.12392635 0.14154634 ... 0.01218013 0.4435894\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.04089366 0.23655783 0.057692   ... 0.0744997  0.35946023\n",
      "    0.2709654 ]\n",
      "   [0.33937612 0.32654223 0.         ... 0.10922622 0.\n",
      "    0.1654859 ]\n",
      "   [0.         0.08437937 0.         ... 0.20362976 0.08554145\n",
      "    0.01376635]]]]\n",
      "[[[[0.         0.04978547 0.18221086 ... 0.19953074 0.1282532\n",
      "    0.2680617 ]\n",
      "   [0.302618   0.25694263 0.         ... 0.03463042 0.\n",
      "    0.11867651]\n",
      "   [0.27616873 0.         0.         ... 0.38341266 0.24167344\n",
      "    0.11720397]\n",
      "   ...\n",
      "   [0.36444086 0.         0.11769362 ... 0.25166047 0.23247501\n",
      "    0.56167454]\n",
      "   [0.07713659 0.3133247  0.17682482 ... 0.         0.31133115\n",
      "    0.18637846]\n",
      "   [0.11211898 0.35029468 0.         ... 0.10008942 0.\n",
      "    0.20824148]]\n",
      "\n",
      "  [[0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]]\n",
      "\n",
      "  [[0.08400626 0.31422445 0.05347278 ... 0.         0.3081212\n",
      "    0.        ]\n",
      "   [0.3645069  0.15861596 0.09122103 ... 0.3123259  0.\n",
      "    0.        ]\n",
      "   [0.12457244 0.         0.28509808 ... 0.08540845 0.06493515\n",
      "    0.08951317]\n",
      "   ...\n",
      "   [0.367194   0.         0.02088073 ... 0.         0.32645756\n",
      "    0.1585792 ]\n",
      "   [0.31254566 0.20956105 0.05495387 ... 0.         0.10131408\n",
      "    0.28503704]\n",
      "   [0.02160883 0.02095209 0.34791303 ... 0.         0.\n",
      "    0.01134947]]\n",
      "\n",
      "  [[0.         0.2513981  0.         ... 0.25217843 0.14240025\n",
      "    0.        ]\n",
      "   [0.30816275 0.25185943 0.02773872 ... 0.16317795 0.\n",
      "    0.2733817 ]\n",
      "   [0.24873488 0.30017382 0.2696395  ... 0.09093179 0.29974478\n",
      "    0.18736912]\n",
      "   ...\n",
      "   [0.13171533 0.         0.14078535 ... 0.06186651 0.16207631\n",
      "    0.2577663 ]\n",
      "   [0.28977412 0.31915677 0.09560438 ... 0.         0.05067979\n",
      "    0.03760877]\n",
      "   [0.         0.5912561  0.         ... 0.14737445 0.03697866\n",
      "    0.4501835 ]]\n",
      "\n",
      "  [[0.07612683 0.14646845 0.         ... 0.22274376 0.09473419\n",
      "    0.38002947]\n",
      "   [0.10375783 0.         0.267613   ... 0.06379259 0.04227642\n",
      "    0.        ]\n",
      "   [0.19828713 0.12392634 0.14154634 ... 0.01218009 0.44358942\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.0408937  0.23655781 0.05769198 ... 0.07449969 0.35946026\n",
      "    0.2709654 ]\n",
      "   [0.3393761  0.32654226 0.         ... 0.10922621 0.\n",
      "    0.16548592]\n",
      "   [0.         0.08437938 0.         ... 0.20362975 0.08554143\n",
      "    0.01376636]]]]\n",
      "-- Infer Time Test --\n",
      "origin model infer time 0.062s\n",
      "fusion model infer time 0.042s\n"
     ]
    }
   ],
   "source": [
    "class QConvBnReLUModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QConvBnReLUModel,self).__init__()\n",
    "        self.conv = nn.Conv2d(3,5,3,bias=True).to(dtype=torch.float)\n",
    "        self.bn = nn.BatchNorm2d(5).to(dtype=torch.float)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        print(f\"before quant: {x.dtype}, Max : {torch.max(x)}, min : {torch.min(x)}\")\n",
    "        x = self.quant(x)\n",
    "        print(f\"after quant : {x.dtype}, Max : {torch.max(x)}, min : {torch.min(x)}\")\n",
    "    \n",
    "        print(f\"self.conv dtype : {self.conv.state_dict()}\")\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "    \n",
    "class ConvBnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(3,5,3,bias=True)\n",
    "        self.bn = nn.BatchNorm2d(5)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "    \n",
    "class ConvBnReLUModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvBnReLUModel,self).__init__()\n",
    "        self.conv = nn.Conv2d(3,5,3,bias=True).to(dtype=torch.float)\n",
    "        self.bn = nn.BatchNorm2d(5).to(dtype=torch.float)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "model = ConvBnReLUModel()\n",
    "# model = QConvBnReLUModel().to(device=torch.device(\"cpu:0\"))\n",
    "model.eval()\n",
    "print(model)\n",
    "# \"fbgemm\" for server , \"qnnpack\" for mobile \n",
    "# model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "\n",
    "# # torch.quantization.fuse_module or myModel.fuse_model()\n",
    "fuse_model = torch.ao.quantization.fuse_modules(model,[['conv','bn','relu']], inplace=False)\n",
    "# fuse_model = model.fuse_model()\n",
    "print(fuse_model)\n",
    "\n",
    "print(f\"-- Equal Test --\")\n",
    "model_eq_check(model, fuse_model, device=torch.device(\"cpu:0\"))\n",
    "\n",
    "\n",
    "print(f\"-- Infer Time Test --\")\n",
    "ori_cpu_time,_ = time_test(model,torch.device(\"cpu\"))\n",
    "fus_cpu_time,_ = time_test(fuse_model,torch.device(\"cpu\"))\n",
    "\n",
    "print(f\"origin model infer time {ori_cpu_time:.3f}s\")\n",
    "print(f\"fusion model infer time {fus_cpu_time:.3f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})\n",
      "QConvBnReLUModel(\n",
      "  (conv): QuantizedConv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0)\n",
      "  (bn): QuantizedBatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (quant): Quantize(scale=tensor([1.]), zero_point=tensor([0]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n",
      "before quant: torch.float32, Max : 0.9950127601623535, min : 0.05630141496658325\n",
      "after quant : torch.quint8, Max : 1, min : 0\n",
      "self.conv dtype : OrderedDict([('weight', tensor([[[[-0.1309, -0.1755,  0.1160],\n",
      "          [ 0.1398, -0.1116,  0.1740],\n",
      "          [ 0.0238, -0.0907,  0.1889]],\n",
      "\n",
      "         [[ 0.0283,  0.0729,  0.0312],\n",
      "          [-0.0476, -0.0833, -0.0178],\n",
      "          [-0.0045,  0.1874, -0.1205]],\n",
      "\n",
      "         [[ 0.0208,  0.1249,  0.1071],\n",
      "          [ 0.0833,  0.1190,  0.1532],\n",
      "          [ 0.0297,  0.0208, -0.0045]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0030,  0.1884, -0.0030],\n",
      "          [ 0.1394, -0.1884,  0.1365],\n",
      "          [ 0.1098,  0.0534, -0.1142]],\n",
      "\n",
      "         [[ 0.0682,  0.0089, -0.0786],\n",
      "          [ 0.1350, -0.0430, -0.1513],\n",
      "          [ 0.0786, -0.0653, -0.0593]],\n",
      "\n",
      "         [[ 0.0771,  0.1706,  0.0668],\n",
      "          [ 0.0564, -0.0430, -0.0490],\n",
      "          [ 0.1528, -0.0757,  0.0030]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0960,  0.1539,  0.1440],\n",
      "          [-0.1384, -0.1581,  0.0325],\n",
      "          [ 0.1017,  0.0551,  0.1228]],\n",
      "\n",
      "         [[-0.0056,  0.1031, -0.1468],\n",
      "          [-0.1186, -0.1002,  0.0748],\n",
      "          [ 0.0353,  0.1793, -0.1426]],\n",
      "\n",
      "         [[ 0.1017,  0.0297,  0.0395],\n",
      "          [-0.0988, -0.1370,  0.1101],\n",
      "          [ 0.0692, -0.1398,  0.0198]]],\n",
      "\n",
      "\n",
      "        [[[-0.0724,  0.1145,  0.0116],\n",
      "          [-0.1246, -0.0580, -0.0956],\n",
      "          [-0.0130,  0.0594, -0.0971]],\n",
      "\n",
      "         [[ 0.0232,  0.0043,  0.1637],\n",
      "          [ 0.0333,  0.0971,  0.0739],\n",
      "          [-0.1753,  0.1840,  0.0782]],\n",
      "\n",
      "         [[ 0.0782,  0.0855, -0.1072],\n",
      "          [-0.0681,  0.1130,  0.1724],\n",
      "          [-0.0478,  0.1782, -0.1579]]],\n",
      "\n",
      "\n",
      "        [[[-0.0426, -0.0426,  0.0455],\n",
      "          [ 0.1101, -0.1601, -0.0015],\n",
      "          [ 0.0719, -0.0323,  0.1865]],\n",
      "\n",
      "         [[ 0.0206,  0.1101,  0.0529],\n",
      "          [ 0.1586,  0.0587,  0.0573],\n",
      "          [-0.0323, -0.1160,  0.1087]],\n",
      "\n",
      "         [[ 0.0308, -0.1806,  0.1307],\n",
      "          [ 0.0250,  0.0514, -0.0793],\n",
      "          [-0.0778,  0.1277, -0.0793]]]], size=(5, 3, 3, 3), dtype=torch.qint8,\n",
      "       quantization_scheme=torch.per_channel_affine,\n",
      "       scale=tensor([0.0015, 0.0015, 0.0014, 0.0014, 0.0015], dtype=torch.float64),\n",
      "       zero_point=tensor([0, 0, 0, 0, 0]), axis=0)), ('bias', Parameter containing:\n",
      "tensor([0.1550, 0.0204, 0.0110, 0.1686, 0.1009], requires_grad=True)), ('scale', tensor(1.)), ('zero_point', tensor(0))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seunmul/.conda/envs/torch/lib/python3.9/site-packages/torch/ao/quantization/observer.py:176: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "/home/seunmul/.conda/envs/torch/lib/python3.9/site-packages/torch/ao/quantization/observer.py:1135: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 1., 0.],\n",
       "          [1., 1., 0.],\n",
       "          [0., 1., 1.]],\n",
       "\n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [1., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 0.]],\n",
       "\n",
       "         [[0., 1., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.],\n",
       "          [0., 1., 1.],\n",
       "          [0., 0., 0.]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = QConvBnReLUModel()\n",
    "M.train()\n",
    "M.qconfig=torch.quantization.get_default_qconfig(\"fbgemm\")\n",
    "print(M.qconfig)\n",
    "torch.quantization.prepare(M,inplace=True)\n",
    "torch.quantization.convert(M,inplace=True)\n",
    "M.eval()\n",
    "print(M)\n",
    "M(torch.rand(1,3,5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cifar10_Dataloader():\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding = 4),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((32,32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root=\"data\", train=True, download=True, transform=train_transform) \n",
    "    # We will use test set for validation and test in this project.\n",
    "    # Do not use test set for validation in practice!\n",
    "    test_dataset = torchvision.datasets.CIFAR10(root=\"data\", train=False, download=True, transform=test_transform)\n",
    "    print(f\"Train data set = {len(train_dataset)}, Test = {len(test_dataset)}\")\n",
    "\n",
    "    train_sampler = torch.utils.data.RandomSampler(train_dataset)\n",
    "    test_sampler = torch.utils.data.SequentialSampler(test_dataset)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset, batch_size=128,\n",
    "        sampler=train_sampler)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_dataset, batch_size=128,\n",
    "        sampler=test_sampler)\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train data set = 50000, Test = 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:02<00:00, 36.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------before----------\n",
      "Validation 6.5055 Loss, 7.67 Acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 19/391 [00:01<00:34, 10.84it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/seunmul/QAT/test.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 103>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bseunmul_temp/home/seunmul/QAT/test.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=107'>108</a>\u001b[0m model1\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bseunmul_temp/home/seunmul/QAT/test.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=108'>109</a>\u001b[0m model1\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bseunmul_temp/home/seunmul/QAT/test.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=109'>110</a>\u001b[0m \u001b[39mfor\u001b[39;00m inputs, labels \u001b[39min\u001b[39;00m tqdm(\u001b[39miter\u001b[39m(train_loader)):\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bseunmul_temp/home/seunmul/QAT/test.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=110'>111</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bseunmul_temp/home/seunmul/QAT/test.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=111'>112</a>\u001b[0m         model2 \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(model1)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torchvision/datasets/cifar.py:118\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    115\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img)\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[1;32m    120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torchvision/transforms/transforms.py:94\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 94\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     95\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torchvision/transforms/transforms.py:678\u001b[0m, in \u001b[0;36mRandomCrop.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    674\u001b[0m     img \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mpad(img, padding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode)\n\u001b[1;32m    676\u001b[0m i, j, h, w \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params(img, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize)\n\u001b[0;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcrop(img, i, j, h, w)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torchvision/transforms/functional.py:504\u001b[0m, in \u001b[0;36mcrop\u001b[0;34m(img, top, left, height, width)\u001b[0m\n\u001b[1;32m    502\u001b[0m     _log_api_usage_once(crop)\n\u001b[1;32m    503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 504\u001b[0m     \u001b[39mreturn\u001b[39;00m F_pil\u001b[39m.\u001b[39;49mcrop(img, top, left, height, width)\n\u001b[1;32m    506\u001b[0m \u001b[39mreturn\u001b[39;00m F_t\u001b[39m.\u001b[39mcrop(img, top, left, height, width)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/torchvision/transforms/functional_pil.py:237\u001b[0m, in \u001b[0;36mcrop\u001b[0;34m(img, top, left, height, width)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_pil_image(img):\n\u001b[1;32m    235\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimg should be PIL Image. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(img)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 237\u001b[0m \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mcrop((left, top, left \u001b[39m+\u001b[39;49m width, top \u001b[39m+\u001b[39;49m height))\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/PIL/Image.py:1176\u001b[0m, in \u001b[0;36mImage.crop\u001b[0;34m(self, box)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCoordinate \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlower\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is less than \u001b[39m\u001b[39m'\u001b[39m\u001b[39mupper\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1175\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload()\n\u001b[0;32m-> 1176\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_crop(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mim, box))\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.9/site-packages/PIL/Image.py:1196\u001b[0m, in \u001b[0;36mImage._crop\u001b[0;34m(self, im, box)\u001b[0m\n\u001b[1;32m   1192\u001b[0m absolute_values \u001b[39m=\u001b[39m (\u001b[39mabs\u001b[39m(x1 \u001b[39m-\u001b[39m x0), \u001b[39mabs\u001b[39m(y1 \u001b[39m-\u001b[39m y0))\n\u001b[1;32m   1194\u001b[0m _decompression_bomb_check(absolute_values)\n\u001b[0;32m-> 1196\u001b[0m \u001b[39mreturn\u001b[39;00m im\u001b[39m.\u001b[39;49mcrop((x0, y0, x1, y1))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def Evaluating(model, test_loader, device, criterion=None):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in tqdm(iter(test_loader)):\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        if criterion is not None:\n",
    "            loss = criterion(outputs, labels).item()\n",
    "        else:\n",
    "            loss = 0\n",
    "        # statistics\n",
    "        running_loss += loss * labels.size(0)\n",
    "        running_corrects += (preds == labels).sum().item()\n",
    "\n",
    "    eval_loss = running_loss / len(test_loader.dataset)\n",
    "    eval_accuracy = 100 * running_corrects / len(test_loader.dataset)\n",
    "\n",
    "    return eval_loss, eval_accuracy\n",
    "\n",
    "def Training(model, train_loader, test_loader, device, optimizer, scheduler, epochs=100,model_name=\"test\"):\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    print(\"Before Training\")\n",
    "    torch.cuda.memory_reserved()\n",
    "    memory_check()\n",
    "    count = 0\n",
    "    best_loss = np.Inf\n",
    "    # Training\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "        model.train()\n",
    "\n",
    "        for inputs, labels in tqdm(iter(train_loader)):\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    " \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            # statistics\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "            running_corrects += (preds == labels).sum().item()\n",
    "\n",
    "            del inputs\n",
    "            del outputs\n",
    "            del loss\n",
    "            del preds\n",
    "        # Set learning rate scheduler\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_accuracy = 100 * running_corrects / len(train_loader.dataset) \n",
    "\n",
    "        # Evaluation\n",
    "        val_loss, val_acc = Evaluating(model,test_loader,device=device,criterion=criterion)\n",
    "        print(f\"--------{epoch}----------\")\n",
    "        print(f\"Train {train_loss:.4f} Loss, {train_accuracy:.2f} Acc\")\n",
    "        print(f\"Validation {val_loss:.4f} Loss, {val_acc:.2f} Acc\")\n",
    "\n",
    "        if best_loss > val_loss:\n",
    "            best_loss = val_loss\n",
    "            count = 0\n",
    "            torch.save(model.state_dict(), f\"./models/{model_name}.pt\")\n",
    "        else:\n",
    "            count +=1\n",
    "            if count > 10:\n",
    "                break\n",
    "    model.load_state_dict(torch.load(f\"./models/{model_name}.pt\")) \n",
    "    return model\n",
    "\n",
    "from models import mobilenet_v2, MobileNet_V2_Weights,quat_mobilenet_v2\n",
    "model1 = mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1,activation_layer=nn.ReLU)\n",
    "model1.classifier.append(nn.Dropout(0.2))\n",
    "model1.classifier.append(nn.Linear(1000, 10))\n",
    "train_loader, test_loader = Cifar10_Dataloader()\n",
    "optimizer = torch.optim.SGD(model1.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "val_loss, val_acc = Evaluating(model1,test_loader,device=device,criterion=criterion)\n",
    "print(f\"--------before----------\")\n",
    "print(f\"Validation {val_loss:.4f} Loss, {val_acc:.2f} Acc\")\n",
    "for i in range(10):\n",
    "    # Training\n",
    "    running_loss1 = 0\n",
    "    running_loss2 = 0\n",
    "    running_corrects = 0\n",
    "    model1.to(device)\n",
    "    model1.train()\n",
    "    for inputs, labels in tqdm(iter(train_loader)):\n",
    "        with torch.no_grad():\n",
    "            model2 = copy.deepcopy(model1)\n",
    "        \n",
    "            inputs1 = inputs.to(device)\n",
    "            inputs2 = inputs.to(device)\n",
    "        \n",
    "            labels = labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        outputs1 = model1(inputs1)\n",
    "        # forward + backward + optimize\n",
    "        outputs2 = model2(inputs2)\n",
    "        loss1 = criterion(outputs1, labels)\n",
    "        loss2 = criterion(outputs2,labels)\n",
    "\n",
    "        loss2.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, preds = torch.max(outputs2, 1)\n",
    "        # statistics\n",
    "        running_loss1 += loss1.item() * labels.size(0)\n",
    "        running_corrects += (preds == labels).sum().item()\n",
    "        running_loss2 += loss2.item() * labels.size(0)\n",
    "    # Set learning rate scheduler\n",
    "    train_loss = running_loss1 / len(train_loader.dataset)\n",
    "    train_loss2 = running_loss2 / len(train_loader.dataset)\n",
    "    train_accuracy = 100 * running_corrects / len(train_loader.dataset) \n",
    "\n",
    "    # Evaluation\n",
    "    val_loss, val_acc = Evaluating(model1,test_loader,device=device,criterion=criterion)\n",
    "    print(f\"--------{i}----------\")\n",
    "    print(f\"Train {train_loss:.4f} Loss, {train_accuracy:.2f} Acc\")\n",
    "    print(f\"Train2 {train_loss2:.4f} Loss, {train_accuracy:.2f} Acc\")\n",
    "    print(f\"Validation {val_loss:.4f} Loss, {val_acc:.2f} Acc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seunmul/.conda/envs/torch/lib/python3.9/site-packages/torch/ao/quantization/observer.py:176: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3308, grad_fn=<MaxBackward1>)\n",
      "tensor(0.1551, grad_fn=<MaxBackward1>)\n",
      "tensor(0.0316, grad_fn=<MaxBackward1>)\n",
      "tensor(0.0272, grad_fn=<MaxBackward1>)\n",
      "Before Training\n",
      "  Allocated: 0.97 GB\n",
      "  Cached:    2.61 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:56<00:00,  6.93it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------0----------\n",
      "Train 1.4654 Loss, 62.71 Acc\n",
      "Validation 1.0464 Loss, 77.65 Acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:56<00:00,  6.91it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------1----------\n",
      "Train 1.0267 Loss, 78.02 Acc\n",
      "Validation 0.9416 Loss, 81.37 Acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:56<00:00,  6.87it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------2----------\n",
      "Train 0.9454 Loss, 81.40 Acc\n",
      "Validation 0.8949 Loss, 83.29 Acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:56<00:00,  6.88it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------3----------\n",
      "Train 0.8934 Loss, 83.70 Acc\n",
      "Validation 0.8944 Loss, 83.46 Acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:56<00:00,  6.91it/s]\n",
      "100%|██████████| 79/79 [00:07<00:00, 10.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------4----------\n",
      "Train 0.8609 Loss, 85.01 Acc\n",
      "Validation 0.8476 Loss, 85.63 Acc\n",
      "tensor(0.3275, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.1534, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0499, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(0.0300, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "model = quat_mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1,activation_layer=nn.ReLU)\n",
    "model.classifier.append(nn.Dropout(0.2))\n",
    "model.classifier.append(nn.Linear(1000, 10))\n",
    "quat_model = model\n",
    "quat_model.fuse_model()\n",
    "\n",
    "quat_model.train()\n",
    "quat_model.qconfig = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
    "quat_model = torch.quantization.prepare_qat(quat_model)\n",
    "copy_model = copy.deepcopy(quat_model)\n",
    "for name, param in copy_model.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        print(torch.max(param))\n",
    " \n",
    "optimizer = torch.optim.SGD(quat_model.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30,60,90], gamma=0.5)\n",
    "\n",
    "quat_model = Training(quat_model,train_loader=train_loader,test_loader=test_loader,device=\"cuda\",optimizer=optimizer,scheduler=scheduler,epochs=1)\n",
    "\n",
    "for name, param in quat_model.named_parameters():\n",
    "    if \"classifier\" in name:\n",
    "        print(torch.max(param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.0.weight\n",
      "features.0.0.bn.weight\n",
      "Parameter containing:\n",
      "tensor([0.0381, 0.1872, 0.1975, 0.2451, 0.1313, 0.1590, 0.0881, 0.2552, 0.0870,\n",
      "        0.0119, 0.4129, 0.1137, 0.2245, 0.3014, 0.0114, 0.0104, 0.0128, 0.0043,\n",
      "        0.0668, 0.4108, 0.3578, 0.1278, 0.5250, 0.0039, 0.4444, 0.1298, 0.3284,\n",
      "        0.2453, 0.3565, 0.3066, 0.4146, 0.1419], requires_grad=True)\n",
      "features.0.0.bn.bias\n",
      "Parameter containing:\n",
      "tensor([-8.4354e-02,  5.6023e-01,  3.5002e-01,  2.8363e-01,  9.7327e-01,\n",
      "         6.4774e-01,  4.9481e-01,  5.5817e-01,  6.1756e-01, -4.2980e-04,\n",
      "        -3.0858e-01,  9.5334e-01,  4.4609e-01, -3.8414e-01, -9.3045e-04,\n",
      "         5.7470e-03, -4.2064e-02, -1.7965e-02,  3.3821e-01,  1.1017e-01,\n",
      "        -2.5284e-01,  5.0251e-01,  3.7990e-01, -1.5532e-02, -4.6869e-01,\n",
      "         5.1056e-01, -2.8880e-01,  6.4006e-01, -1.0935e-01, -5.9483e-02,\n",
      "         3.7479e-01,  2.6511e-01], requires_grad=True)\n",
      "features.1.conv.0.0.weight\n",
      "features.1.conv.0.0.bn.weight\n",
      "features.1.conv.0.0.bn.bias\n",
      "features.1.conv.1.weight\n",
      "features.1.conv.1.bn.weight\n",
      "features.1.conv.1.bn.bias\n",
      "features.2.conv.0.0.weight\n",
      "features.2.conv.0.0.bn.weight\n",
      "features.2.conv.0.0.bn.bias\n",
      "features.2.conv.1.0.weight\n",
      "features.2.conv.1.0.bn.weight\n",
      "features.2.conv.1.0.bn.bias\n",
      "features.2.conv.2.weight\n",
      "features.2.conv.2.bn.weight\n",
      "features.2.conv.2.bn.bias\n",
      "features.3.conv.0.0.weight\n",
      "features.3.conv.0.0.bn.weight\n",
      "features.3.conv.0.0.bn.bias\n",
      "features.3.conv.1.0.weight\n",
      "features.3.conv.1.0.bn.weight\n",
      "features.3.conv.1.0.bn.bias\n",
      "features.3.conv.2.weight\n",
      "features.3.conv.2.bn.weight\n",
      "features.3.conv.2.bn.bias\n",
      "features.4.conv.0.0.weight\n",
      "features.4.conv.0.0.bn.weight\n",
      "features.4.conv.0.0.bn.bias\n",
      "features.4.conv.1.0.weight\n",
      "features.4.conv.1.0.bn.weight\n",
      "features.4.conv.1.0.bn.bias\n",
      "features.4.conv.2.weight\n",
      "features.4.conv.2.bn.weight\n",
      "features.4.conv.2.bn.bias\n",
      "features.5.conv.0.0.weight\n",
      "features.5.conv.0.0.bn.weight\n",
      "features.5.conv.0.0.bn.bias\n",
      "features.5.conv.1.0.weight\n",
      "features.5.conv.1.0.bn.weight\n",
      "features.5.conv.1.0.bn.bias\n",
      "features.5.conv.2.weight\n",
      "features.5.conv.2.bn.weight\n",
      "features.5.conv.2.bn.bias\n",
      "features.6.conv.0.0.weight\n",
      "features.6.conv.0.0.bn.weight\n",
      "features.6.conv.0.0.bn.bias\n",
      "features.6.conv.1.0.weight\n",
      "features.6.conv.1.0.bn.weight\n",
      "features.6.conv.1.0.bn.bias\n",
      "features.6.conv.2.weight\n",
      "features.6.conv.2.bn.weight\n",
      "features.6.conv.2.bn.bias\n",
      "features.7.conv.0.0.weight\n",
      "features.7.conv.0.0.bn.weight\n",
      "features.7.conv.0.0.bn.bias\n",
      "features.7.conv.1.0.weight\n",
      "features.7.conv.1.0.bn.weight\n",
      "features.7.conv.1.0.bn.bias\n",
      "features.7.conv.2.weight\n",
      "features.7.conv.2.bn.weight\n",
      "features.7.conv.2.bn.bias\n",
      "features.8.conv.0.0.weight\n",
      "features.8.conv.0.0.bn.weight\n",
      "features.8.conv.0.0.bn.bias\n",
      "features.8.conv.1.0.weight\n",
      "features.8.conv.1.0.bn.weight\n",
      "features.8.conv.1.0.bn.bias\n",
      "features.8.conv.2.weight\n",
      "features.8.conv.2.bn.weight\n",
      "features.8.conv.2.bn.bias\n",
      "features.9.conv.0.0.weight\n",
      "features.9.conv.0.0.bn.weight\n",
      "features.9.conv.0.0.bn.bias\n",
      "features.9.conv.1.0.weight\n",
      "features.9.conv.1.0.bn.weight\n",
      "features.9.conv.1.0.bn.bias\n",
      "features.9.conv.2.weight\n",
      "features.9.conv.2.bn.weight\n",
      "features.9.conv.2.bn.bias\n",
      "features.10.conv.0.0.weight\n",
      "features.10.conv.0.0.bn.weight\n",
      "features.10.conv.0.0.bn.bias\n",
      "features.10.conv.1.0.weight\n",
      "features.10.conv.1.0.bn.weight\n",
      "features.10.conv.1.0.bn.bias\n",
      "features.10.conv.2.weight\n",
      "features.10.conv.2.bn.weight\n",
      "features.10.conv.2.bn.bias\n",
      "features.11.conv.0.0.weight\n",
      "features.11.conv.0.0.bn.weight\n",
      "features.11.conv.0.0.bn.bias\n",
      "features.11.conv.1.0.weight\n",
      "features.11.conv.1.0.bn.weight\n",
      "features.11.conv.1.0.bn.bias\n",
      "features.11.conv.2.weight\n",
      "features.11.conv.2.bn.weight\n",
      "features.11.conv.2.bn.bias\n",
      "features.12.conv.0.0.weight\n",
      "features.12.conv.0.0.bn.weight\n",
      "features.12.conv.0.0.bn.bias\n",
      "features.12.conv.1.0.weight\n",
      "features.12.conv.1.0.bn.weight\n",
      "features.12.conv.1.0.bn.bias\n",
      "features.12.conv.2.weight\n",
      "features.12.conv.2.bn.weight\n",
      "features.12.conv.2.bn.bias\n",
      "features.13.conv.0.0.weight\n",
      "features.13.conv.0.0.bn.weight\n",
      "features.13.conv.0.0.bn.bias\n",
      "features.13.conv.1.0.weight\n",
      "features.13.conv.1.0.bn.weight\n",
      "features.13.conv.1.0.bn.bias\n",
      "features.13.conv.2.weight\n",
      "features.13.conv.2.bn.weight\n",
      "features.13.conv.2.bn.bias\n",
      "features.14.conv.0.0.weight\n",
      "features.14.conv.0.0.bn.weight\n",
      "features.14.conv.0.0.bn.bias\n",
      "features.14.conv.1.0.weight\n",
      "features.14.conv.1.0.bn.weight\n",
      "features.14.conv.1.0.bn.bias\n",
      "features.14.conv.2.weight\n",
      "features.14.conv.2.bn.weight\n",
      "features.14.conv.2.bn.bias\n",
      "features.15.conv.0.0.weight\n",
      "features.15.conv.0.0.bn.weight\n",
      "features.15.conv.0.0.bn.bias\n",
      "features.15.conv.1.0.weight\n",
      "features.15.conv.1.0.bn.weight\n",
      "features.15.conv.1.0.bn.bias\n",
      "features.15.conv.2.weight\n",
      "features.15.conv.2.bn.weight\n",
      "features.15.conv.2.bn.bias\n",
      "features.16.conv.0.0.weight\n",
      "features.16.conv.0.0.bn.weight\n",
      "features.16.conv.0.0.bn.bias\n",
      "features.16.conv.1.0.weight\n",
      "features.16.conv.1.0.bn.weight\n",
      "features.16.conv.1.0.bn.bias\n",
      "features.16.conv.2.weight\n",
      "features.16.conv.2.bn.weight\n",
      "features.16.conv.2.bn.bias\n",
      "features.17.conv.0.0.weight\n",
      "features.17.conv.0.0.bn.weight\n",
      "features.17.conv.0.0.bn.bias\n",
      "features.17.conv.1.0.weight\n",
      "features.17.conv.1.0.bn.weight\n",
      "features.17.conv.1.0.bn.bias\n",
      "features.17.conv.2.weight\n",
      "features.17.conv.2.bn.weight\n",
      "features.17.conv.2.bn.bias\n",
      "features.18.0.weight\n",
      "features.18.0.bn.weight\n",
      "features.18.0.bn.bias\n",
      "classifier.1.weight\n",
      "classifier.1.weight torch.Size([1000, 1280])\n",
      "tensor(0.3308) tensor(-0.2456)\n",
      "Parameter containing:\n",
      "tensor([[-3.1177e-02,  8.9587e-02, -7.4812e-02,  ..., -3.3275e-02,\n",
      "         -6.3844e-02, -4.2156e-02],\n",
      "        [-2.2173e-02,  5.4803e-02,  1.2471e-02,  ..., -4.2400e-02,\n",
      "         -2.5825e-02,  1.2331e-02],\n",
      "        [-6.9285e-03,  2.1576e-02, -3.0861e-02,  ..., -7.2696e-02,\n",
      "         -6.1196e-02, -5.7697e-03],\n",
      "        ...,\n",
      "        [-4.4350e-02,  2.8589e-02, -2.1555e-02,  ..., -2.9260e-02,\n",
      "         -4.3549e-02,  6.3868e-02],\n",
      "        [-1.9761e-02,  1.3970e-01,  4.8443e-02,  ..., -9.5596e-03,\n",
      "          1.5066e-03,  1.2227e-04],\n",
      "        [ 5.1320e-02,  3.0963e-02,  6.9039e-02,  ...,  5.7984e-03,\n",
      "         -5.5186e-03, -2.5348e-02]], requires_grad=True)\n",
      "tensor([[-27.,   4., -38.,  ..., -27., -35., -29.],\n",
      "        [-24.,  -5., -16.,  ..., -30., -25., -16.],\n",
      "        [-21., -13., -27.,  ..., -37., -34., -20.],\n",
      "        ...,\n",
      "        [-30., -12., -24.,  ..., -26., -30.,  -3.],\n",
      "        [-24.,  17.,  -6.,  ..., -21., -18., -19.],\n",
      "        [ -6., -11.,  -1.,  ..., -17., -20., -25.]])\n",
      "tensor(65.) tensor(-81.)\n",
      "classifier.1.bias\n",
      "classifier.1.bias torch.Size([1000])\n",
      "tensor(0.1551) tensor(-0.1208)\n",
      "Parameter containing:\n",
      "tensor([ 4.7188e-02,  9.9494e-03, -3.3395e-02, -5.1339e-02,  1.1923e-02,\n",
      "         2.2345e-02, -1.7384e-02, -1.1905e-02,  1.3966e-02, -5.4831e-03,\n",
      "        -1.3473e-02, -4.1479e-02, -2.6590e-02, -1.6171e-02,  7.9140e-03,\n",
      "        -2.7376e-03, -3.7561e-02, -4.8437e-02,  1.4724e-02,  7.4215e-03,\n",
      "         2.0747e-02,  7.8874e-02,  5.0797e-02, -1.3168e-02,  1.6659e-02,\n",
      "        -7.8493e-03,  2.6460e-02,  8.2619e-03,  2.2761e-02, -4.9684e-03,\n",
      "         2.4963e-02,  3.9342e-03, -9.4261e-03, -7.2999e-03,  2.2262e-02,\n",
      "        -4.4321e-02,  2.0107e-02, -1.0940e-02, -2.2117e-03, -7.6674e-03,\n",
      "        -3.6928e-03,  3.9186e-02,  9.1523e-03, -4.0572e-02, -1.3912e-02,\n",
      "        -2.8831e-03,  4.1178e-02, -1.1824e-02, -2.9012e-02, -1.6900e-02,\n",
      "         3.6710e-02, -1.8870e-02,  2.1097e-02,  5.4457e-02, -3.1022e-02,\n",
      "        -1.7617e-02, -1.0715e-02, -1.7957e-03,  4.7776e-02,  5.0959e-02,\n",
      "        -5.3010e-02, -1.1235e-02, -2.8151e-02,  5.4345e-02,  5.9299e-02,\n",
      "         2.4955e-02, -3.6163e-02, -4.0120e-02,  1.4444e-02,  1.8140e-02,\n",
      "        -3.3614e-02,  1.7372e-02,  6.9826e-03, -3.3872e-03, -5.4271e-02,\n",
      "         5.0368e-02, -6.0656e-03,  1.9089e-02,  6.1446e-02,  2.9232e-02,\n",
      "        -1.3014e-02,  1.9138e-02,  2.2493e-02, -9.3810e-02, -5.9287e-02,\n",
      "         3.2079e-04, -3.2066e-02,  1.8010e-02, -7.7150e-03,  5.9154e-02,\n",
      "        -8.4715e-03, -3.7302e-02,  2.7756e-02, -3.9616e-02, -4.7572e-02,\n",
      "        -5.3029e-02,  2.0620e-02, -4.8253e-02, -4.0293e-02, -3.7067e-02,\n",
      "        -3.1563e-02, -2.9158e-03,  9.1531e-03,  7.8593e-02,  2.3209e-02,\n",
      "        -2.1354e-02, -8.7965e-03,  2.6277e-03, -4.0205e-02, -5.8108e-02,\n",
      "        -6.6817e-02,  1.3153e-01,  1.0830e-02, -3.3254e-02, -1.1682e-02,\n",
      "        -1.0267e-01,  5.9913e-03, -1.1838e-02,  8.2734e-03, -3.4770e-02,\n",
      "         1.4876e-02, -4.3105e-02, -3.3930e-02, -4.8522e-02, -2.6185e-02,\n",
      "        -2.6696e-02, -2.9869e-02, -1.2027e-02, -1.1313e-02, -5.7537e-03,\n",
      "        -3.8506e-02,  2.5785e-03,  2.8609e-02,  1.2248e-02, -9.2905e-02,\n",
      "        -6.0920e-02, -2.3947e-02, -2.4319e-02, -1.6570e-02, -4.7439e-02,\n",
      "        -3.6951e-02, -4.9971e-03, -4.1001e-02,  1.1922e-02, -6.1892e-02,\n",
      "        -1.8962e-02,  3.2866e-03, -3.3938e-02, -8.5421e-03,  3.0039e-02,\n",
      "        -4.3798e-02, -4.0750e-02, -6.6313e-02,  9.3524e-02, -4.7197e-02,\n",
      "        -7.9530e-03,  6.6232e-03, -2.1693e-02, -5.1803e-02, -2.1488e-02,\n",
      "        -2.3326e-03,  1.8778e-02,  6.2436e-02,  1.4403e-02, -1.6043e-02,\n",
      "        -2.3351e-02,  7.0256e-03, -7.7242e-02,  2.2514e-02, -7.0590e-03,\n",
      "         3.4560e-03,  4.2522e-02,  1.0525e-02, -3.2754e-03,  1.7745e-02,\n",
      "        -3.5665e-02, -2.0160e-02, -3.9915e-02,  7.3782e-02,  1.1141e-02,\n",
      "         2.9864e-03, -2.5500e-02, -5.3120e-03, -3.9071e-02, -9.4456e-03,\n",
      "         1.5621e-02, -2.7844e-02, -7.6019e-03, -3.4986e-02, -1.7296e-02,\n",
      "        -2.9212e-03,  3.2789e-02,  2.5646e-02, -5.1394e-02,  1.4590e-02,\n",
      "         7.0804e-02,  2.3230e-02,  6.3046e-03, -4.6503e-02,  5.1973e-02,\n",
      "        -9.7841e-02, -4.0067e-03,  3.4386e-02,  5.1423e-02,  3.4976e-02,\n",
      "        -7.6068e-03, -5.9308e-02, -2.7020e-05, -3.5011e-02,  1.8797e-02,\n",
      "        -2.5047e-02,  2.7007e-03, -3.4164e-02, -2.1186e-02, -2.4063e-02,\n",
      "        -1.6193e-02, -8.8174e-04,  6.3239e-02,  3.1755e-02, -2.6025e-02,\n",
      "        -4.0378e-02, -4.4135e-02, -1.3881e-02,  9.5376e-02, -6.4276e-02,\n",
      "         3.8923e-02, -2.8703e-02, -1.3521e-02, -6.4742e-02,  1.9885e-02,\n",
      "         1.8955e-02, -4.1160e-02,  2.5638e-02, -5.9921e-03,  2.4106e-02,\n",
      "        -2.2638e-02,  7.6559e-02,  6.1563e-02, -1.2732e-02,  6.5307e-02,\n",
      "        -4.1131e-02, -1.6505e-02,  4.8044e-03, -1.5116e-02, -2.4251e-02,\n",
      "         3.3845e-02, -4.7577e-02,  1.3693e-02, -3.9343e-02, -4.3481e-02,\n",
      "        -3.5408e-02,  4.4748e-02,  2.7723e-02, -5.9710e-02,  4.0661e-02,\n",
      "        -2.4895e-02, -1.3437e-02, -1.1087e-02,  9.1081e-03,  6.2954e-03,\n",
      "         3.3406e-02, -6.0265e-04, -4.7090e-02,  2.0630e-02,  3.5595e-03,\n",
      "        -3.0545e-02,  1.6862e-02, -7.1483e-02, -5.7713e-02, -6.8388e-03,\n",
      "         7.9959e-02, -3.1863e-02, -1.5330e-02, -1.7397e-02, -2.9826e-02,\n",
      "        -3.9866e-02,  3.5178e-02, -7.3802e-03, -3.2513e-02,  3.5019e-02,\n",
      "        -2.3596e-02,  8.7193e-02, -8.5256e-02, -3.9008e-02,  5.9088e-02,\n",
      "         2.6075e-02,  2.7165e-02, -5.2599e-03, -3.2125e-02, -8.0124e-03,\n",
      "        -1.3041e-02, -4.0398e-02,  4.5141e-03, -1.8924e-02, -6.3506e-03,\n",
      "        -2.2675e-02, -1.3221e-02,  1.0075e-03,  1.0981e-02,  4.2909e-02,\n",
      "        -2.1585e-02, -5.3533e-03, -3.3323e-03, -1.8797e-02, -3.8427e-02,\n",
      "         5.6927e-02,  5.3915e-03, -1.5122e-02,  1.3636e-02,  5.3920e-03,\n",
      "         1.6431e-02,  3.4429e-03,  1.7370e-02,  4.2204e-02,  3.5237e-02,\n",
      "        -1.1677e-02,  1.3238e-04, -2.7822e-02,  2.8695e-02, -1.8132e-02,\n",
      "        -3.2596e-02, -7.1280e-02, -7.3362e-02, -2.2656e-02, -4.8683e-02,\n",
      "        -3.8766e-02, -1.1406e-02, -5.4143e-03, -2.8433e-02, -2.0233e-02,\n",
      "        -1.5239e-02, -2.5263e-02,  5.8656e-04,  6.8991e-03,  1.3175e-03,\n",
      "        -3.7726e-02,  3.6378e-02, -2.7854e-02, -4.9275e-02, -9.0432e-03,\n",
      "         5.7164e-03, -5.6063e-02, -2.3068e-02, -3.1633e-02, -3.2353e-02,\n",
      "        -7.1407e-03,  2.6191e-02, -2.4548e-03, -3.1404e-02, -1.7929e-02,\n",
      "         1.9925e-02,  3.0236e-03, -2.6462e-02,  1.1979e-02,  1.4642e-03,\n",
      "        -2.8124e-02, -2.7856e-02, -7.9922e-03, -7.8572e-03,  5.4966e-02,\n",
      "         1.3543e-02,  6.1273e-02,  5.4430e-03, -1.5038e-03, -6.2640e-03,\n",
      "         2.1142e-02, -1.1447e-02,  4.8628e-02, -2.7560e-02,  5.5910e-02,\n",
      "        -4.2130e-02, -3.1600e-02, -1.7323e-02, -1.1033e-02,  2.0862e-02,\n",
      "        -2.1668e-02,  4.5613e-03, -2.3059e-02,  2.1830e-02,  2.5815e-02,\n",
      "        -6.8977e-02, -1.4668e-02,  1.5410e-02,  3.2170e-02, -6.5074e-02,\n",
      "        -2.1060e-02,  6.2372e-03, -1.8393e-02, -2.1328e-02, -3.5702e-02,\n",
      "        -7.3291e-02,  2.1668e-02, -3.9123e-02, -4.3788e-02, -2.9927e-02,\n",
      "        -2.5776e-02, -6.0908e-02, -4.0892e-02, -2.4972e-02,  3.7685e-02,\n",
      "        -5.7151e-02,  4.2181e-03, -3.3003e-03,  2.9448e-03, -5.3260e-02,\n",
      "         5.8279e-02,  9.9559e-03, -4.0885e-02, -5.9346e-02, -5.3783e-02,\n",
      "         2.5646e-02,  3.5061e-03,  3.8744e-02,  7.9240e-02,  3.4342e-02,\n",
      "        -1.0990e-02,  5.5301e-02, -5.4885e-02,  7.4463e-02,  9.0414e-03,\n",
      "        -2.1821e-02, -3.1500e-02, -1.3923e-02,  1.0192e-01,  5.9579e-02,\n",
      "         1.6526e-02, -1.0504e-01, -5.3532e-02, -6.8957e-03,  1.6561e-03,\n",
      "         1.1959e-02,  2.6299e-02, -1.1180e-02,  2.6977e-03, -5.2712e-02,\n",
      "         2.6224e-02,  2.9105e-02, -1.8765e-02,  7.1490e-03, -3.6568e-02,\n",
      "        -1.7147e-02,  1.9740e-02, -1.3175e-02,  1.5520e-02,  3.0138e-02,\n",
      "         6.1970e-02,  5.2493e-02,  8.7747e-03,  8.2896e-02,  3.0328e-02,\n",
      "         6.6819e-03,  4.3412e-03, -4.7677e-02,  2.2827e-02,  1.5254e-02,\n",
      "        -1.4792e-02,  3.0391e-02,  4.9802e-02, -2.1044e-02,  5.8306e-02,\n",
      "         5.0853e-03,  1.6510e-02, -5.4492e-03, -4.6784e-03,  4.6354e-02,\n",
      "         7.5714e-03,  7.1766e-04,  6.8577e-03,  5.1527e-02, -1.3745e-02,\n",
      "         8.7565e-02, -4.7596e-02,  2.8862e-03,  3.5373e-02, -2.5218e-02,\n",
      "        -1.1688e-02, -5.0211e-02, -1.8439e-02, -5.4764e-02, -7.7586e-02,\n",
      "         2.1901e-02,  1.3246e-04, -3.0145e-02, -9.3757e-03, -9.9327e-03,\n",
      "         6.2210e-03,  4.0513e-03,  3.8259e-02,  4.6178e-02,  3.4756e-02,\n",
      "        -7.7334e-02,  2.5491e-02,  2.6299e-02, -5.5790e-03, -2.5501e-02,\n",
      "        -9.6644e-03,  1.8773e-02, -5.6645e-02,  4.0383e-02,  2.0928e-02,\n",
      "        -3.9355e-02, -3.0002e-03, -4.4836e-03, -3.2955e-03,  2.2328e-02,\n",
      "         2.6134e-02,  6.9439e-03, -9.2179e-03, -1.2414e-02,  1.3489e-02,\n",
      "        -7.7219e-03,  1.0975e-02, -6.6068e-03,  2.0020e-02,  1.4744e-02,\n",
      "         9.4194e-04,  3.3192e-02, -7.1490e-02, -7.0094e-02,  1.4764e-02,\n",
      "        -2.7508e-02, -1.1399e-04,  1.8251e-02,  7.4128e-02, -3.0926e-02,\n",
      "        -2.1262e-02,  1.6323e-02,  1.1584e-02, -1.6408e-02,  1.0061e-01,\n",
      "         4.0787e-02, -4.1952e-02,  4.2706e-02,  3.4696e-02,  1.3033e-02,\n",
      "         1.9541e-02, -6.5632e-03,  3.1103e-03,  1.5453e-03,  2.9099e-03,\n",
      "        -5.6684e-02,  1.1210e-02, -3.7264e-04, -4.7211e-03, -3.5078e-03,\n",
      "         2.0667e-02,  8.0475e-03, -4.7696e-02, -3.0853e-02,  7.2040e-02,\n",
      "         9.1017e-03,  1.8865e-02, -4.8023e-02,  1.1332e-02, -1.4428e-02,\n",
      "        -2.2093e-02, -2.9545e-03,  3.4834e-02, -3.2843e-02,  4.5704e-02,\n",
      "        -1.0285e-02,  1.0591e-02,  2.8585e-03,  6.9149e-02, -2.6638e-02,\n",
      "         1.3036e-03, -1.2448e-03,  2.5912e-02, -1.2751e-02,  1.9244e-02,\n",
      "        -3.1852e-02,  5.4605e-03,  1.6166e-02,  3.3802e-03,  3.3979e-02,\n",
      "         1.0907e-02,  3.1348e-02, -1.9345e-02, -1.4828e-02,  1.5114e-02,\n",
      "        -8.2193e-03, -2.3346e-02,  2.4552e-02,  3.1931e-02,  5.0237e-02,\n",
      "        -5.1021e-02, -1.5275e-02,  2.4327e-02,  4.1875e-03,  1.0406e-02,\n",
      "        -1.0062e-02, -2.9562e-02, -4.7802e-03,  7.6118e-02, -3.1206e-02,\n",
      "        -2.5875e-02,  5.3581e-04,  1.8974e-02, -1.7886e-02, -1.2178e-02,\n",
      "         9.4171e-03,  4.5759e-02,  3.5802e-02,  8.5478e-04, -1.0565e-02,\n",
      "         2.8955e-02,  7.7932e-03,  2.3669e-02,  5.0250e-02,  6.0112e-03,\n",
      "         4.4736e-02, -3.1303e-02, -3.7995e-02, -3.4515e-02, -2.4386e-02,\n",
      "         2.2533e-02,  3.1891e-02, -3.1320e-03,  2.5413e-02, -2.5762e-02,\n",
      "         4.2446e-02,  1.7164e-02,  1.1279e-02,  8.8087e-02, -3.0057e-02,\n",
      "        -1.3569e-02,  3.5042e-02,  3.3222e-02, -1.6305e-02,  5.0539e-02,\n",
      "         3.9449e-02, -3.3715e-02,  2.6012e-02, -2.3923e-02,  3.1856e-02,\n",
      "        -2.1604e-02,  7.2538e-02, -2.6053e-02, -3.9638e-02, -2.8962e-02,\n",
      "        -6.5323e-02,  4.1914e-03,  1.9159e-02, -2.6297e-02,  5.9906e-02,\n",
      "        -7.1511e-03,  1.3680e-01, -5.4451e-02,  4.2376e-02,  4.3985e-02,\n",
      "         7.5189e-02, -1.8508e-02, -2.6088e-02,  9.2823e-03,  3.6877e-02,\n",
      "         8.1504e-02,  3.5321e-02,  2.7666e-02, -2.3958e-03,  2.2024e-02,\n",
      "         3.1363e-02, -2.1484e-02,  5.8938e-02,  2.2853e-02,  4.3841e-02,\n",
      "         5.7227e-02,  9.0185e-03,  1.0238e-02, -3.1602e-02, -2.6930e-02,\n",
      "         1.7767e-02,  9.8776e-02,  5.0997e-02,  4.6717e-02,  3.0014e-02,\n",
      "        -5.1009e-02, -1.2080e-01,  9.5313e-02,  4.2246e-02,  2.0330e-04,\n",
      "         5.5999e-04,  2.4044e-02,  2.2419e-02,  7.2298e-02,  7.5483e-02,\n",
      "         1.4355e-02, -7.5368e-03, -8.5577e-03, -5.3579e-02, -6.6469e-02,\n",
      "        -4.5164e-02, -5.0136e-03,  6.9394e-02, -5.1719e-02, -8.6219e-04,\n",
      "         4.7444e-02,  7.8976e-03, -1.3381e-02,  1.5904e-02, -1.2848e-02,\n",
      "         4.4607e-02,  1.0156e-02, -6.9930e-02,  5.6569e-02,  4.7577e-02,\n",
      "        -5.0996e-02,  2.8220e-02,  1.4690e-04,  2.9994e-03, -1.6294e-02,\n",
      "        -1.3050e-02, -2.9207e-02, -8.5719e-03, -2.7210e-04, -5.3412e-03,\n",
      "         1.6923e-02,  8.2102e-02, -3.0297e-02,  2.7408e-02,  3.2689e-02,\n",
      "        -1.7249e-03, -2.1103e-02,  3.0428e-02, -2.6437e-02, -2.8636e-02,\n",
      "        -4.5792e-03,  8.5358e-03, -1.1218e-02, -5.1603e-02, -2.4389e-03,\n",
      "        -1.4825e-02,  2.2624e-02,  2.7795e-02, -6.0308e-03, -2.1175e-02,\n",
      "         2.1915e-02, -7.0012e-03,  1.1365e-02,  3.6313e-02,  6.7886e-02,\n",
      "        -1.0858e-02,  1.6994e-02, -6.0924e-02,  7.2244e-02, -1.6417e-02,\n",
      "         3.6126e-02,  2.0419e-02,  3.2265e-02, -8.7980e-03,  4.0922e-02,\n",
      "         1.6929e-02, -1.8463e-02,  6.1332e-02,  2.8618e-02, -2.1771e-02,\n",
      "         1.0885e-02,  2.3297e-02, -5.2983e-02,  4.3721e-02,  4.8953e-03,\n",
      "         2.2934e-02, -4.4510e-02, -3.3859e-02, -1.6118e-03,  1.0661e-02,\n",
      "         1.9244e-03, -1.8144e-02,  5.1802e-02,  3.2137e-02,  1.4183e-02,\n",
      "        -2.9755e-02, -2.8657e-02,  4.0211e-02,  3.4449e-02,  5.5293e-02,\n",
      "        -2.2290e-03,  2.8468e-02,  3.7091e-02, -3.0840e-02, -9.4719e-03,\n",
      "        -4.4498e-02, -9.1779e-03,  1.8184e-02,  3.1879e-02,  2.6583e-02,\n",
      "         1.4751e-02, -3.1356e-02, -6.3764e-02,  7.7525e-04, -7.5631e-03,\n",
      "        -7.0021e-02,  3.2364e-02, -4.3038e-03, -2.6475e-03,  1.0875e-02,\n",
      "         1.9744e-03,  6.1003e-03,  9.1544e-03, -3.1207e-02,  1.7208e-02,\n",
      "        -1.5643e-02,  1.9290e-03, -1.3671e-03, -3.6624e-03, -3.1683e-02,\n",
      "        -1.6273e-02, -3.9202e-02, -2.0426e-02, -2.0162e-02, -3.1245e-02,\n",
      "        -6.7422e-02, -4.5393e-02,  3.5576e-02,  1.0199e-02,  2.9711e-04,\n",
      "        -5.1524e-02, -4.0179e-02,  2.7816e-02, -1.0137e-03,  2.6981e-02,\n",
      "        -9.5051e-03,  2.2844e-02,  4.8468e-02,  2.0231e-02,  2.9364e-02,\n",
      "         4.4785e-02, -1.1804e-02, -3.6539e-03,  3.2059e-02, -2.5649e-02,\n",
      "         3.8923e-02,  6.6193e-02, -3.1607e-03, -3.8406e-03,  6.9912e-02,\n",
      "        -4.7133e-03,  5.6442e-02,  1.1724e-02,  7.4726e-02,  1.2409e-02,\n",
      "         2.3347e-02,  2.3509e-02,  4.2675e-02,  4.2924e-02,  2.0624e-02,\n",
      "         7.5664e-02,  3.2412e-02,  7.2500e-03,  6.0445e-03,  1.8407e-02,\n",
      "         8.5192e-03, -2.8560e-02, -9.9416e-03, -2.4943e-02, -3.9373e-02,\n",
      "        -3.7436e-04, -4.9055e-02, -2.6024e-02,  5.9523e-02,  7.3581e-02,\n",
      "        -8.4242e-03,  5.9382e-02, -5.4772e-02,  5.7358e-02, -3.7112e-02,\n",
      "        -2.3236e-02, -3.0020e-02,  9.9133e-03,  7.8539e-02, -2.3426e-02,\n",
      "         2.6434e-02, -1.5053e-02,  4.9082e-03, -1.7651e-02, -3.5343e-02,\n",
      "        -8.2517e-03,  1.8954e-03,  3.5386e-03, -4.7270e-02,  7.3528e-02,\n",
      "         3.7670e-02,  2.6883e-03, -8.8049e-03, -2.5146e-02,  2.7871e-02,\n",
      "         1.5510e-01, -3.5320e-02, -2.7405e-02,  2.3640e-02,  2.2111e-02,\n",
      "         3.2186e-03,  1.0051e-02,  5.3235e-02,  6.8113e-02, -4.9403e-02,\n",
      "         4.0111e-02,  4.3836e-02, -6.5971e-03,  4.1623e-02, -5.6431e-02,\n",
      "         7.8285e-03,  7.3700e-03,  4.5066e-02,  1.8078e-02, -1.5131e-03,\n",
      "         6.9669e-02,  8.8572e-02,  5.8604e-03, -1.8109e-02,  8.5833e-03,\n",
      "        -2.9794e-02,  2.2775e-02, -2.6451e-02, -1.7217e-02,  1.1735e-02,\n",
      "        -2.1490e-02, -6.5574e-02, -8.8835e-02, -4.3085e-03,  8.0337e-02,\n",
      "         1.0596e-02, -4.0670e-02, -4.5243e-04, -3.7244e-03, -6.1672e-02,\n",
      "        -4.1474e-02, -3.2676e-02,  3.0729e-02, -3.3924e-02,  6.9074e-02,\n",
      "         2.8953e-02, -3.3917e-02,  5.5786e-03, -2.9308e-02, -1.6690e-02,\n",
      "        -1.5147e-02, -3.4159e-04, -2.4404e-02, -1.8894e-02, -3.6188e-02,\n",
      "        -1.0405e-02, -1.9025e-02, -3.5500e-02, -2.9449e-02, -2.5749e-02,\n",
      "         2.2558e-05, -2.5413e-02, -4.6285e-02, -1.1534e-02, -1.9694e-02,\n",
      "        -3.4743e-02, -4.0784e-02,  4.2564e-02, -2.4938e-02, -3.0604e-02,\n",
      "        -1.3716e-02, -1.4360e-04, -2.8983e-02,  1.2522e-02, -4.8045e-02,\n",
      "        -3.1591e-02, -1.4765e-03, -2.9696e-02, -2.8902e-02, -3.2108e-02,\n",
      "         2.0092e-02,  7.0335e-02,  2.8177e-02, -4.3897e-02,  6.3684e-02,\n",
      "        -5.3940e-02,  2.9984e-02, -3.0883e-03, -5.8680e-03,  4.5470e-02,\n",
      "        -1.6744e-02,  6.9474e-02,  6.6445e-02,  3.0672e-02, -1.6758e-02,\n",
      "         4.8870e-02,  1.5709e-02,  5.7927e-02, -2.3677e-02,  6.2093e-03,\n",
      "         1.8138e-02, -2.9314e-02, -3.0099e-02, -3.8977e-02,  7.3863e-03,\n",
      "         8.7005e-03, -1.3437e-02, -2.6017e-02, -7.8447e-02, -1.8236e-02,\n",
      "        -3.0466e-02, -1.0147e-03, -2.8219e-02, -4.6351e-03, -3.2482e-03],\n",
      "       requires_grad=True)\n",
      "tensor([ -4., -13., -24., -29., -13., -10., -20., -19., -12., -17., -19., -26.,\n",
      "        -23., -20., -14., -16., -25., -28., -12., -14., -11.,   4.,  -3., -19.,\n",
      "        -12., -18.,  -9., -14., -10., -17.,  -9., -15., -18., -18., -10., -27.,\n",
      "        -11., -19., -16., -18., -17.,  -6., -13., -26., -19., -17.,  -5., -19.,\n",
      "        -23., -20.,  -6., -21., -10.,  -2., -24., -20., -19., -16.,  -4.,  -3.,\n",
      "        -29., -19., -23.,  -2.,  -1.,  -9., -25., -26., -12., -11., -24., -11.,\n",
      "        -14., -17., -30.,  -3., -17., -11.,  -0.,  -8., -19., -11., -10., -40.,\n",
      "        -31., -16., -24., -11., -18.,  -1., -18., -25.,  -9., -26., -28., -29.,\n",
      "        -11., -28., -26., -25., -24., -17., -13.,   4., -10., -21., -18., -15.,\n",
      "        -26., -31., -33.,  18., -13., -24., -19., -42., -14., -19., -14., -25.,\n",
      "        -12., -27., -24., -28., -22., -23., -23., -19., -19., -17., -26., -15.,\n",
      "         -9., -13., -39., -31., -22., -22., -20., -28., -25., -17., -26., -13.,\n",
      "        -32., -21., -15., -24., -18.,  -8., -27., -26., -33.,   8., -28., -18.,\n",
      "        -14., -21., -29., -21., -16., -11.,   0., -12., -20., -22., -14., -35.,\n",
      "        -10., -18., -15.,  -5., -13., -17., -11., -25., -21., -26.,   3., -13.,\n",
      "        -15., -22., -17., -26., -18., -12., -23., -18., -25., -20., -17.,  -7.,\n",
      "         -9., -29., -12.,   2., -10., -14., -28.,  -3., -41., -17.,  -7.,  -3.,\n",
      "         -7., -18., -31., -16., -25., -11., -22., -15., -24., -21., -22., -20.,\n",
      "        -16.,   0.,  -8., -22., -26., -27., -19.,   8., -32.,  -6., -23., -19.,\n",
      "        -32., -11., -11., -26.,  -9., -17., -10., -22.,   4.,  -0., -19.,   1.,\n",
      "        -26., -20., -15., -20., -22.,  -7., -28., -12., -26., -27., -25.,  -4.,\n",
      "         -9., -31.,  -5., -22., -19., -19., -13., -14.,  -7., -16., -28., -11.,\n",
      "        -15., -24., -12., -34., -30., -18.,   5., -24., -20., -20., -23., -26.,\n",
      "         -7., -18., -24.,  -7., -22.,   6., -37., -26.,  -1.,  -9.,  -9., -17.,\n",
      "        -24., -18., -19., -26., -15., -21., -17., -22., -19., -16., -13.,  -5.,\n",
      "        -21., -17., -17., -21., -26.,  -1., -14., -20., -12., -14., -12., -15.,\n",
      "        -11.,  -5.,  -7., -19., -16., -23.,  -8., -20., -24., -34., -34., -22.,\n",
      "        -28., -26., -19., -17., -23., -21., -20., -22., -16., -14., -15., -25.,\n",
      "         -7., -23., -28., -18., -14., -30., -22., -24., -24., -18.,  -9., -16.,\n",
      "        -24., -20., -11., -15., -23., -13., -15., -23., -23., -18., -18.,  -2.,\n",
      "        -12.,  -0., -14., -16., -17., -10., -19.,  -3., -23.,  -2., -26., -24.,\n",
      "        -20., -19., -10., -21., -15., -22., -10.,  -9., -33., -20., -12.,  -8.,\n",
      "        -32., -21., -14., -20., -21., -25., -34., -10., -26., -27., -23., -22.,\n",
      "        -31., -26., -22.,  -6., -30., -15., -17., -15., -29.,  -1., -13., -26.,\n",
      "        -31., -29.,  -9., -15.,  -6.,   4.,  -7., -19.,  -2., -30.,   3., -13.,\n",
      "        -21., -24., -19.,  10.,  -1., -12., -42., -29., -18., -15., -13.,  -9.,\n",
      "        -19., -15., -29.,  -9.,  -8., -21., -14., -25., -20., -11., -19., -12.,\n",
      "         -8.,  -0.,  -2., -14.,   5.,  -8., -14., -15., -28., -10., -12., -20.,\n",
      "         -8.,  -3., -21.,  -1., -14., -12., -17., -17.,  -4., -14., -16., -14.,\n",
      "         -3., -19.,   6., -28., -15.,  -7., -22., -19., -29., -20., -30., -35.,\n",
      "        -10., -16., -23., -18., -18., -14., -15.,  -6.,  -4.,  -7., -35.,  -9.,\n",
      "         -9., -17., -22., -18., -11., -30.,  -6., -10., -26., -17., -17., -17.,\n",
      "        -10.,  -9., -14., -18., -19., -12., -18., -13., -17., -11., -12., -16.,\n",
      "         -7., -34., -34., -12., -23., -16., -11.,   3., -24., -21., -12., -13.,\n",
      "        -20.,  10.,  -5., -26.,  -5.,  -7., -12., -11., -17., -15., -15., -15.,\n",
      "        -30., -13., -16., -17., -17., -11., -14., -28., -24.,   3., -13., -11.,\n",
      "        -28., -13., -19., -21., -17.,  -7., -24.,  -4., -18., -13., -15.,   2.,\n",
      "        -23., -15., -16.,  -9., -19., -11., -24., -14., -12., -15.,  -7., -13.,\n",
      "         -8., -21., -20., -12., -18., -22., -10.,  -8.,  -3., -29., -20., -10.,\n",
      "        -15., -13., -18., -23., -17.,   4., -24., -22., -16., -11., -20., -19.,\n",
      "        -13.,  -4.,  -7., -16., -18.,  -8., -14., -10.,  -3., -14.,  -4., -24.,\n",
      "        -25., -25., -22., -10.,  -8., -17.,  -9., -22.,  -5., -11., -13.,   7.,\n",
      "        -23., -19.,  -7.,  -7., -20.,  -3.,  -6., -24.,  -9., -22.,  -8., -21.,\n",
      "          3., -22., -26., -23., -32., -15., -11., -22.,  -1., -18.,  19., -30.,\n",
      "         -5.,  -5.,   3., -20., -22., -13.,  -6.,   5.,  -7.,  -9., -16., -10.,\n",
      "         -8., -21.,  -1., -10.,  -5.,  -1., -13., -13., -24., -23., -11.,   9.,\n",
      "         -3.,  -4.,  -8., -29., -46.,   8.,  -5., -16., -16., -10., -10.,   3.,\n",
      "          3., -12., -18., -18., -29., -33., -27., -17.,   2., -29., -16.,  -4.,\n",
      "        -14., -19., -12., -19.,  -4., -13., -34.,  -1.,  -4., -29.,  -9., -16.,\n",
      "        -15., -20., -19., -23., -18., -16., -17., -11.,   5., -23.,  -9.,  -7.,\n",
      "        -16., -21.,  -8., -23., -23., -17., -14., -19., -29., -16., -20., -10.,\n",
      "         -9., -17., -21., -10., -18., -13.,  -7.,   1., -19., -11., -31.,   3.,\n",
      "        -20.,  -7., -11.,  -8., -18.,  -5., -11., -20.,  -0.,  -9., -21., -13.,\n",
      "        -10., -29.,  -5., -15., -10., -27., -24., -16., -13., -15., -20.,  -3.,\n",
      "         -8., -12., -23., -23.,  -6.,  -7.,  -2., -16.,  -9.,  -6., -24., -18.,\n",
      "        -27., -18., -11.,  -8.,  -9., -12., -24., -32., -16., -18., -34.,  -8.,\n",
      "        -17., -16., -13., -15., -14., -13., -24., -11., -20., -15., -16., -17.,\n",
      "        -24., -20., -26., -21., -21., -24., -33., -27.,  -7., -13., -16., -29.,\n",
      "        -26.,  -9., -16.,  -9., -18., -10.,  -3., -11.,  -8.,  -4., -19., -17.,\n",
      "         -8., -22.,  -6.,   1., -17., -17.,   2., -17.,  -1., -13.,   3., -13.,\n",
      "        -10., -10.,  -5.,  -5., -11.,   3.,  -8., -14., -14., -11., -14., -23.,\n",
      "        -18., -22., -26., -16., -28., -22.,  -1.,   3., -18.,  -1., -30.,  -1.,\n",
      "        -25., -22., -23., -13.,   4., -22.,  -9., -20., -15., -20., -25., -18.,\n",
      "        -15., -15., -28.,   3.,  -6., -15., -18., -22.,  -9.,  24., -25., -23.,\n",
      "        -10., -10., -15., -13.,  -2.,   2., -28.,  -6.,  -5., -17.,  -5., -30.,\n",
      "        -14., -14.,  -4., -11., -16.,   2.,   7., -14., -20., -14., -23., -10.,\n",
      "        -23., -20., -13., -21., -32., -38., -17.,   5., -13., -26., -16., -17.,\n",
      "        -31., -26., -24.,  -8., -24.,   2.,  -8., -24., -14., -23., -20., -20.,\n",
      "        -16., -22., -21., -25., -18., -21., -25., -23., -22., -16., -22., -28.,\n",
      "        -19., -21., -25., -26.,  -5., -22., -24., -19., -16., -23., -13., -28.,\n",
      "        -24., -16., -23., -23., -24., -11.,   2.,  -9., -27.,   0., -29.,  -8.,\n",
      "        -17., -17.,  -4., -20.,   2.,   1.,  -8., -20.,  -3., -12.,  -1., -22.,\n",
      "        -14., -11., -23., -23., -26., -14., -14., -19., -22., -36., -20., -24.,\n",
      "        -16., -23., -17., -17.])\n",
      "tensor(24.) tensor(-46.)\n",
      "classifier.3.weight\n",
      "classifier.3.weight torch.Size([10, 1000])\n",
      "tensor(0.0316) tensor(-0.0316)\n",
      "Parameter containing:\n",
      "tensor([[-0.0082, -0.0026,  0.0218,  ..., -0.0180, -0.0011, -0.0095],\n",
      "        [-0.0266,  0.0090, -0.0004,  ..., -0.0141,  0.0275,  0.0059],\n",
      "        [-0.0145, -0.0192, -0.0249,  ...,  0.0300, -0.0189,  0.0082],\n",
      "        ...,\n",
      "        [ 0.0039,  0.0002,  0.0232,  ...,  0.0275,  0.0316, -0.0217],\n",
      "        [-0.0215, -0.0210, -0.0029,  ...,  0.0039,  0.0022, -0.0316],\n",
      "        [-0.0236,  0.0030,  0.0037,  ..., -0.0077, -0.0131, -0.0063]],\n",
      "       requires_grad=True)\n",
      "tensor([[-2., -1.,  6.,  ..., -5., -0., -2.],\n",
      "        [-7.,  2., -0.,  ..., -4.,  7.,  1.],\n",
      "        [-4., -5., -6.,  ...,  8., -5.,  2.],\n",
      "        ...,\n",
      "        [ 1.,  0.,  6.,  ...,  7.,  8., -6.],\n",
      "        [-5., -5., -1.,  ...,  1.,  1., -8.],\n",
      "        [-6.,  1.,  1.,  ..., -2., -3., -2.]])\n",
      "tensor(8.) tensor(-8.)\n",
      "classifier.3.bias\n",
      "classifier.3.bias torch.Size([10])\n",
      "tensor(0.0272) tensor(-0.0220)\n",
      "Parameter containing:\n",
      "tensor([-0.0126, -0.0146,  0.0272,  0.0112, -0.0181,  0.0004,  0.0255,  0.0212,\n",
      "         0.0238, -0.0220], requires_grad=True)\n",
      "tensor([-17., -17.,  -7., -11., -18., -13.,  -7.,  -8.,  -7., -19.])\n",
      "tensor(-7.) tensor(-19.)\n",
      "--------------------------------------------------\n",
      "tensor(0.3275, device='cuda:0') tensor(-0.2429, device='cuda:0')\n",
      "tensor(0.1534, device='cuda:0') tensor(-0.1194, device='cuda:0')\n",
      "tensor(0.0499, device='cuda:0') tensor(-0.0429, device='cuda:0')\n",
      "tensor(0.0300, device='cuda:0') tensor(-0.0248, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    copy_model.eval()\n",
    "    for name, param in copy_model.named_parameters():\n",
    "        print(name)\n",
    "        if \"classifier\" in name:\n",
    "            print(name,param.shape)\n",
    "            ma = torch.max(param)\n",
    "            mi = torch.min(param)\n",
    "            print(ma, mi)\n",
    "            print(param)\n",
    "            cal = torch.round((127*2*(param-mi/(ma-mi))-127),decimals=0)\n",
    "            print(cal)\n",
    "            print(torch.max(cal), torch.min(cal))\n",
    "        else:\n",
    "            if \"features.0.0.bn.weight\" in name:\n",
    "                print(param)\n",
    "            elif \"features.0.0.bn.bias\" in name:\n",
    "                print(param)\n",
    "            \n",
    "    print(\"-\"*50)\n",
    "    for name, param in quat_model.named_parameters():\n",
    "        if \"classifier\" in name:\n",
    "            print(torch.max(param),torch.min(param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters())\n",
    "for i in range(epoch):\n",
    "    for inputs, labels in tqdm(iter(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model = weight_quant(model)\n",
    "            input = weight_quant(input)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        outputs = model(inputs)\n",
    "        with torch.no_grad():\n",
    "            model = weight_dequant(model)\n",
    "        # forward + backward + optimize\n",
    "        loss = criterion(outputs, labels) * scale\n",
    "\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        # statistics\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "        running_corrects += (preds == labels).sum().item()\n",
    "\n",
    "    # Set learning rate scheduler\n",
    "    train_loss = running_loss1 / len(train_loader.dataset)\n",
    "    train_accuracy = 100 * running_corrects / len(train_loader.dataset) \n",
    "\n",
    "    # Evaluation\n",
    "    val_loss, val_acc = Evaluating(model1,test_loader,device=device,criterion=criterion)\n",
    "    print(f\"--------{i}----------\")\n",
    "    print(f\"Train {train_loss:.4f} Loss, {train_accuracy:.2f} Acc\")\n",
    "    print(f\"Train2 {train_loss2:.4f} Loss, {train_accuracy:.2f} Acc\")\n",
    "    print(f\"Validation {val_loss:.4f} Loss, {val_acc:.2f} Acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters())\n",
    "for i in range(epoch):\n",
    "    for inputs, labels in tqdm(iter(train_loader)):\n",
    "        with torch.no_grad():\n",
    "            quant_model = quantize(model)\n",
    "            inputs1 = inputs.to(device)\n",
    "            inputs2 = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs1 = model(inputs1)\n",
    "        outputs2 = quant_model(inputs2)\n",
    "        # forward + backward + optimize\n",
    "        loss1 = criterion(outputs1, labels)\n",
    "        loss2 = criterion(outputs2,labels)\n",
    "        \n",
    "        total_loss = total(loss1,loss2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, preds = torch.max(outputs2, 1)\n",
    "        # statistics\n",
    "        running_loss1 += loss1.item() * labels.size(0)\n",
    "        running_corrects += (preds == labels).sum().item()\n",
    "        running_loss2 += loss2.item() * labels.size(0)\n",
    "    # Set learning rate scheduler\n",
    "    train_loss = running_loss1 / len(train_loader.dataset)\n",
    "    train_loss2 = running_loss2 / len(train_loader.dataset)\n",
    "    train_accuracy = 100 * running_corrects / len(train_loader.dataset) \n",
    "\n",
    "    # Evaluation\n",
    "    val_loss, val_acc = Evaluating(model,test_loader,device=device,criterion=criterion)\n",
    "    print(f\"--------{i}----------\")\n",
    "    print(f\"Train {train_loss:.4f} Loss, {train_accuracy:.2f} Acc\")\n",
    "    print(f\"Train2 {train_loss2:.4f} Loss, {train_accuracy:.2f} Acc\")\n",
    "    print(f\"Validation {val_loss:.4f} Loss, {val_acc:.2f} Acc\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24c3f2c56578ca93d34255952c36601b421b6ecc37a0d9982e6b92a246c07692"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
